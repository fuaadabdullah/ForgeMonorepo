# Fly.io configuration for lightweight API backend
# Models run on separate servers (RunPod, Aliyun, on-prem)
# This app is API-only - routes requests to remote model servers

app = "goblin-backend"
primary_region = "iad"

[build]
dockerfile = "Dockerfile.prod"

[env]
PORT = "8001"
ENVIRONMENT = "production"
LOG_LEVEL = "INFO"

[http_service]
internal_port = 8001
force_https = true
auto_stop_machines = "stop"
auto_start_machines = true
min_machines_running = 1
processes = ["app"]

[[http_service.checks]]
grace_period = "30s"
interval = "30s"
method = "GET"
path = "/health"
protocol = "http"
timeout = "10s"

# Reduced VM resources since no models run here
[[vm]]
memory = "1gb"      # Down from 4gb - no model loading
cpu_kind = "shared"
cpus = 1            # Down from 2 - API-only

[[mounts]]
source = "data"
destination = "/app/data"

# Required runtime secrets for remote model servers:
# RunPod (primary):
#   fly secrets set RUNPOD_ENDPOINT_URL=https://api.runpod.io/v1/...
#   fly secrets set RUNPOD_API_KEY=rpa_...
#
# Aliyun GPU (secondary):
#   fly secrets set ALIYUN_MODEL_SERVER_URL=http://aliyun-instance-ip:11434
#   fly secrets set ALIYUN_MODEL_SERVER_KEY=<optional-api-key>
#
# On-prem/local (tertiary):
#   fly secrets set ONPREM_MODEL_SERVER_URL=https://your-domain.com
#   fly secrets set ONPREM_MODEL_SERVER_KEY=<optional-api-key>
#
# See MODEL_SERVER_DEPLOYMENT.md for setup instructions
