{
  "version": 4,
  "terraform_version": "1.5.7",
  "serial": 35,
  "lineage": "afedb423-4a92-037d-3c8b-aaf5ede7b2a0",
  "outputs": {
    "llamacpp_vm_public_ip": {
      "value": "34.31.129.66",
      "type": "string"
    },
    "llamacpp_vm_static_ip": {
      "value": "34.31.129.66",
      "type": "string"
    },
    "ollama_vm_private_ip": {
      "value": "10.70.0.5",
      "type": "string"
    },
    "ollama_vm_public_ip": {
      "value": "34.59.191.226",
      "type": "string"
    },
    "ollama_vm_static_ip": {
      "value": "34.59.191.226",
      "type": "string"
    }
  },
  "resources": [
    {
      "mode": "managed",
      "type": "google_compute_address",
      "name": "llamacpp_static",
      "provider": "provider[\"registry.terraform.io/hashicorp/google\"]",
      "instances": [
        {
          "index_key": 0,
          "schema_version": 0,
          "attributes": {
            "address": "34.31.129.66",
            "address_type": "EXTERNAL",
            "creation_timestamp": "2026-02-13T06:37:53.301-08:00",
            "description": "",
            "effective_labels": {
              "goog-terraform-provisioned": "true"
            },
            "id": "projects/goblin-assistant-479511/regions/us-central1/addresses/llamacpp-server-static-ip",
            "ip_collection": "",
            "ip_version": "",
            "ipv6_endpoint_type": "",
            "label_fingerprint": "vezUS-42LLM=",
            "labels": {},
            "name": "llamacpp-server-static-ip",
            "network": "",
            "network_tier": "PREMIUM",
            "prefix_length": 0,
            "project": "goblin-assistant-479511",
            "purpose": "",
            "region": "us-central1",
            "self_link": "https://www.googleapis.com/compute/v1/projects/goblin-assistant-479511/regions/us-central1/addresses/llamacpp-server-static-ip",
            "subnetwork": "",
            "terraform_labels": {
              "goog-terraform-provisioned": "true"
            },
            "timeouts": null,
            "users": [
              "https://www.googleapis.com/compute/v1/projects/goblin-assistant-479511/zones/us-central1-a/instances/llamacpp-server"
            ]
          },
          "sensitive_attributes": [],
          "private": "eyJlMmJmYjczMC1lY2FhLTExZTYtOGY4OC0zNDM2M2JjN2M0YzAiOnsiY3JlYXRlIjoxMjAwMDAwMDAwMDAwLCJkZWxldGUiOjEyMDAwMDAwMDAwMDAsInVwZGF0ZSI6MTIwMDAwMDAwMDAwMH19"
        }
      ]
    },
    {
      "mode": "managed",
      "type": "google_compute_address",
      "name": "ollama_static",
      "provider": "provider[\"registry.terraform.io/hashicorp/google\"]",
      "instances": [
        {
          "index_key": 0,
          "schema_version": 0,
          "attributes": {
            "address": "34.59.191.226",
            "address_type": "EXTERNAL",
            "creation_timestamp": "2026-02-13T07:04:00.404-08:00",
            "description": "",
            "effective_labels": {
              "goog-terraform-provisioned": "true"
            },
            "id": "projects/goblin-assistant-479511/regions/us-central1/addresses/ollama-gpu-static-ip",
            "ip_collection": "",
            "ip_version": "",
            "ipv6_endpoint_type": "",
            "label_fingerprint": "vezUS-42LLM=",
            "labels": {},
            "name": "ollama-gpu-static-ip",
            "network": "",
            "network_tier": "PREMIUM",
            "prefix_length": 0,
            "project": "goblin-assistant-479511",
            "purpose": "",
            "region": "us-central1",
            "self_link": "https://www.googleapis.com/compute/v1/projects/goblin-assistant-479511/regions/us-central1/addresses/ollama-gpu-static-ip",
            "subnetwork": "",
            "terraform_labels": {
              "goog-terraform-provisioned": "true"
            },
            "timeouts": null,
            "users": [
              "https://www.googleapis.com/compute/v1/projects/goblin-assistant-479511/zones/us-central1-a/instances/ollama-gpu"
            ]
          },
          "sensitive_attributes": [],
          "private": "eyJlMmJmYjczMC1lY2FhLTExZTYtOGY4OC0zNDM2M2JjN2M0YzAiOnsiY3JlYXRlIjoxMjAwMDAwMDAwMDAwLCJkZWxldGUiOjEyMDAwMDAwMDAwMDAsInVwZGF0ZSI6MTIwMDAwMDAwMDAwMH19"
        }
      ]
    },
    {
      "mode": "managed",
      "type": "google_compute_firewall",
      "name": "llamacpp_allow",
      "provider": "provider[\"registry.terraform.io/hashicorp/google\"]",
      "instances": [
        {
          "index_key": 0,
          "schema_version": 1,
          "attributes": {
            "allow": [
              {
                "ports": [
                  "8080"
                ],
                "protocol": "tcp"
              }
            ],
            "creation_timestamp": "2026-02-13T06:38:14.982-08:00",
            "deny": [],
            "description": "",
            "destination_ranges": [],
            "direction": "INGRESS",
            "disabled": false,
            "enable_logging": null,
            "id": "projects/goblin-assistant-479511/global/firewalls/llamacpp-server-allow-llamacpp",
            "log_config": [],
            "name": "llamacpp-server-allow-llamacpp",
            "network": "https://www.googleapis.com/compute/v1/projects/goblin-assistant-479511/global/networks/llm-net",
            "params": [],
            "priority": 1000,
            "project": "goblin-assistant-479511",
            "self_link": "https://www.googleapis.com/compute/v1/projects/goblin-assistant-479511/global/firewalls/llamacpp-server-allow-llamacpp",
            "source_ranges": [
              "107.211.127.151/32",
              "216.246.40.171/32"
            ],
            "source_service_accounts": [],
            "source_tags": [],
            "target_service_accounts": [],
            "target_tags": [
              "llamacpp-server"
            ],
            "timeouts": null
          },
          "sensitive_attributes": [],
          "private": "eyJlMmJmYjczMC1lY2FhLTExZTYtOGY4OC0zNDM2M2JjN2M0YzAiOnsiY3JlYXRlIjoxMjAwMDAwMDAwMDAwLCJkZWxldGUiOjEyMDAwMDAwMDAwMDAsInVwZGF0ZSI6MTIwMDAwMDAwMDAwMH0sInNjaGVtYV92ZXJzaW9uIjoiMSJ9",
          "dependencies": [
            "google_compute_network.llm"
          ]
        }
      ]
    },
    {
      "mode": "managed",
      "type": "google_compute_firewall",
      "name": "ollama_allow",
      "provider": "provider[\"registry.terraform.io/hashicorp/google\"]",
      "instances": [
        {
          "index_key": 0,
          "schema_version": 1,
          "attributes": {
            "allow": [
              {
                "ports": [
                  "11434"
                ],
                "protocol": "tcp"
              }
            ],
            "creation_timestamp": "2026-02-13T07:04:00.573-08:00",
            "deny": [],
            "description": "",
            "destination_ranges": [],
            "direction": "INGRESS",
            "disabled": false,
            "enable_logging": null,
            "id": "projects/goblin-assistant-479511/global/firewalls/ollama-gpu-allow-ollama",
            "log_config": [],
            "name": "ollama-gpu-allow-ollama",
            "network": "https://www.googleapis.com/compute/v1/projects/goblin-assistant-479511/global/networks/llm-net",
            "params": [],
            "priority": 1000,
            "project": "goblin-assistant-479511",
            "self_link": "https://www.googleapis.com/compute/v1/projects/goblin-assistant-479511/global/firewalls/ollama-gpu-allow-ollama",
            "source_ranges": [
              "107.211.127.151/32",
              "216.246.40.171/32"
            ],
            "source_service_accounts": [],
            "source_tags": [],
            "target_service_accounts": [],
            "target_tags": [
              "ollama-gpu"
            ],
            "timeouts": null
          },
          "sensitive_attributes": [],
          "private": "eyJlMmJmYjczMC1lY2FhLTExZTYtOGY4OC0zNDM2M2JjN2M0YzAiOnsiY3JlYXRlIjoxMjAwMDAwMDAwMDAwLCJkZWxldGUiOjEyMDAwMDAwMDAwMDAsInVwZGF0ZSI6MTIwMDAwMDAwMDAwMH0sInNjaGVtYV92ZXJzaW9uIjoiMSJ9",
          "dependencies": [
            "google_compute_network.llm"
          ]
        }
      ]
    },
    {
      "mode": "managed",
      "type": "google_compute_instance",
      "name": "llamacpp",
      "provider": "provider[\"registry.terraform.io/hashicorp/google\"]",
      "instances": [
        {
          "index_key": 0,
          "schema_version": 6,
          "attributes": {
            "advanced_machine_features": [],
            "allow_stopping_for_update": null,
            "attached_disk": [],
            "boot_disk": [
              {
                "auto_delete": true,
                "device_name": "persistent-disk-0",
                "disk_encryption_key_raw": "",
                "disk_encryption_key_rsa": "",
                "disk_encryption_key_sha256": "",
                "disk_encryption_service_account": "",
                "force_attach": false,
                "guest_os_features": [
                  "VIRTIO_SCSI_MULTIQUEUE",
                  "SEV_CAPABLE",
                  "SEV_SNP_CAPABLE",
                  "SEV_LIVE_MIGRATABLE",
                  "SEV_LIVE_MIGRATABLE_V2",
                  "IDPF",
                  "TDX_CAPABLE",
                  "UEFI_COMPATIBLE",
                  "GVNIC"
                ],
                "initialize_params": [
                  {
                    "architecture": "X86_64",
                    "enable_confidential_compute": false,
                    "image": "https://www.googleapis.com/compute/v1/projects/ubuntu-os-cloud/global/images/ubuntu-2204-jammy-v20260210",
                    "labels": {},
                    "provisioned_iops": 0,
                    "provisioned_throughput": 0,
                    "resource_manager_tags": null,
                    "resource_policies": [],
                    "size": 200,
                    "snapshot": "",
                    "source_image_encryption_key": [],
                    "source_snapshot_encryption_key": [],
                    "storage_pool": "",
                    "type": "pd-ssd"
                  }
                ],
                "interface": "",
                "kms_key_self_link": "",
                "mode": "READ_WRITE",
                "source": "https://www.googleapis.com/compute/v1/projects/goblin-assistant-479511/zones/us-central1-a/disks/llamacpp-server"
              }
            ],
            "can_ip_forward": false,
            "confidential_instance_config": [],
            "cpu_platform": "AMD Rome",
            "creation_timestamp": "2026-02-13T07:36:04.129-08:00",
            "current_status": "RUNNING",
            "deletion_protection": false,
            "description": "",
            "desired_status": null,
            "effective_labels": {
              "goog-terraform-provisioned": "true"
            },
            "enable_display": false,
            "guest_accelerator": [],
            "hostname": "",
            "id": "projects/goblin-assistant-479511/zones/us-central1-a/instances/llamacpp-server",
            "instance_encryption_key": [],
            "instance_id": "5568004929980922380",
            "key_revocation_action_type": "",
            "label_fingerprint": "vezUS-42LLM=",
            "labels": null,
            "machine_type": "e2-standard-8",
            "metadata": null,
            "metadata_fingerprint": "gepadhVnxUc=",
            "metadata_startup_script": "#!/usr/bin/env bash\nset -euo pipefail\n\napt-get update -y\napt-get install -y curl ca-certificates\n\nif ! command -v docker \u003e/dev/null 2\u003e\u00261; then\n  curl -fsSL https://get.docker.com | sh\n  systemctl enable docker\n  systemctl restart docker\nfi\n\nmkdir -p /opt/llamacpp/models\nMODEL_PATH=\"/opt/llamacpp/models/model.gguf\"\nMODEL_URL=\"https://huggingface.co/TheBloke/TinyLlama-1.1B-Chat-v1.0-GGUF/resolve/main/tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf\"\n\nif [ ! -s \"$MODEL_PATH\" ]; then\n  echo \"[llamacpp] Downloading model: $MODEL_URL\"\n  curl -fL --retry 6 --retry-delay 5 --retry-all-errors -o \"${MODEL_PATH}.tmp\" \"$MODEL_URL\"\n  mv \"${MODEL_PATH}.tmp\" \"$MODEL_PATH\"\nfi\n\ncat \u003e /etc/systemd/system/llamacpp.service \u003c\u003c'EOF'\n[Unit]\nDescription=llama.cpp OpenAI-compatible server\nAfter=network-online.target docker.service\nRequires=docker.service\nWants=network-online.target\n\n[Service]\nRestart=always\nRestartSec=5\nExecStartPre=-/usr/bin/docker rm -f llamacpp-server\nExecStart=/usr/bin/docker run --name llamacpp-server --network host -v /opt/llamacpp/models:/models ghcr.io/ggml-org/llama.cpp:server \\\n  --host 0.0.0.0 --port 8080 -m /models/model.gguf --ctx-size 4096\nExecStop=/usr/bin/docker stop llamacpp-server\n\n[Install]\nWantedBy=multi-user.target\nEOF\n\nsystemctl daemon-reload\nsystemctl enable llamacpp\nsystemctl restart llamacpp\n\n# Best-effort startup verification for diagnostics.\nfor i in $(seq 1 30); do\n  if curl -sf --max-time 2 \"http://127.0.0.1:8080/v1/models\" \u003e/dev/null 2\u003e\u00261; then\n    echo \"[llamacpp] API healthy on :8080\"\n    exit 0\n  fi\n  sleep 2\ndone\necho \"[llamacpp] API not healthy after startup window\"\n",
            "min_cpu_platform": "",
            "name": "llamacpp-server",
            "network_interface": [
              {
                "access_config": [
                  {
                    "nat_ip": "34.31.129.66",
                    "network_tier": "PREMIUM",
                    "public_ptr_domain_name": ""
                  }
                ],
                "alias_ip_range": [],
                "igmp_query": "",
                "internal_ipv6_prefix_length": 0,
                "ipv6_access_config": [],
                "ipv6_access_type": "",
                "ipv6_address": "",
                "name": "nic0",
                "network": "https://www.googleapis.com/compute/v1/projects/goblin-assistant-479511/global/networks/llm-net",
                "network_attachment": "",
                "network_ip": "10.70.0.8",
                "nic_type": "",
                "parent_nic_name": "",
                "queue_count": 0,
                "stack_type": "IPV4_ONLY",
                "subnetwork": "https://www.googleapis.com/compute/v1/projects/goblin-assistant-479511/regions/us-central1/subnetworks/llm-subnet",
                "subnetwork_project": "goblin-assistant-479511",
                "vlan": 0
              }
            ],
            "network_performance_config": [],
            "params": [],
            "project": "goblin-assistant-479511",
            "reservation_affinity": [],
            "resource_policies": null,
            "scheduling": [
              {
                "automatic_restart": true,
                "availability_domain": 0,
                "instance_termination_action": "",
                "local_ssd_recovery_timeout": [],
                "max_run_duration": [],
                "min_node_cpus": 0,
                "node_affinities": [],
                "on_host_maintenance": "MIGRATE",
                "on_instance_stop_action": [],
                "preemptible": false,
                "provisioning_model": "STANDARD",
                "termination_time": ""
              }
            ],
            "scratch_disk": [],
            "self_link": "https://www.googleapis.com/compute/v1/projects/goblin-assistant-479511/zones/us-central1-a/instances/llamacpp-server",
            "service_account": [
              {
                "email": "llm-runtime@goblin-assistant-479511.iam.gserviceaccount.com",
                "scopes": [
                  "https://www.googleapis.com/auth/cloud-platform"
                ]
              }
            ],
            "shielded_instance_config": [
              {
                "enable_integrity_monitoring": true,
                "enable_secure_boot": false,
                "enable_vtpm": true
              }
            ],
            "tags": [
              "llamacpp-server"
            ],
            "tags_fingerprint": "FcbXtU9yhk8=",
            "terraform_labels": {
              "goog-terraform-provisioned": "true"
            },
            "timeouts": null,
            "zone": "us-central1-a"
          },
          "sensitive_attributes": [],
          "private": "eyJlMmJmYjczMC1lY2FhLTExZTYtOGY4OC0zNDM2M2JjN2M0YzAiOnsiY3JlYXRlIjoxMjAwMDAwMDAwMDAwLCJkZWxldGUiOjEyMDAwMDAwMDAwMDAsInVwZGF0ZSI6MTIwMDAwMDAwMDAwMH0sInNjaGVtYV92ZXJzaW9uIjoiNiJ9",
          "dependencies": [
            "google_compute_address.llamacpp_static",
            "google_compute_network.llm",
            "google_compute_subnetwork.llm",
            "google_service_account.llm"
          ]
        }
      ]
    },
    {
      "mode": "managed",
      "type": "google_compute_instance",
      "name": "ollama",
      "provider": "provider[\"registry.terraform.io/hashicorp/google\"]",
      "instances": [
        {
          "index_key": 0,
          "schema_version": 6,
          "attributes": {
            "advanced_machine_features": [],
            "allow_stopping_for_update": null,
            "attached_disk": [],
            "boot_disk": [
              {
                "auto_delete": true,
                "device_name": "persistent-disk-0",
                "disk_encryption_key_raw": "",
                "disk_encryption_key_rsa": "",
                "disk_encryption_key_sha256": "",
                "disk_encryption_service_account": "",
                "force_attach": false,
                "guest_os_features": [
                  "VIRTIO_SCSI_MULTIQUEUE",
                  "SEV_CAPABLE",
                  "SEV_SNP_CAPABLE",
                  "SEV_LIVE_MIGRATABLE",
                  "SEV_LIVE_MIGRATABLE_V2",
                  "IDPF",
                  "TDX_CAPABLE",
                  "UEFI_COMPATIBLE",
                  "GVNIC"
                ],
                "initialize_params": [
                  {
                    "architecture": "X86_64",
                    "enable_confidential_compute": false,
                    "image": "https://www.googleapis.com/compute/v1/projects/ubuntu-os-cloud/global/images/ubuntu-2204-jammy-v20260210",
                    "labels": {},
                    "provisioned_iops": 0,
                    "provisioned_throughput": 0,
                    "resource_manager_tags": {},
                    "resource_policies": [],
                    "size": 200,
                    "snapshot": "",
                    "source_image_encryption_key": [],
                    "source_snapshot_encryption_key": [],
                    "storage_pool": "",
                    "type": "pd-ssd"
                  }
                ],
                "interface": "",
                "kms_key_self_link": "",
                "mode": "READ_WRITE",
                "source": "https://www.googleapis.com/compute/v1/projects/goblin-assistant-479511/zones/us-central1-a/disks/ollama-gpu"
              }
            ],
            "can_ip_forward": false,
            "confidential_instance_config": [],
            "cpu_platform": "Intel Broadwell",
            "creation_timestamp": "2026-02-13T07:14:14.668-08:00",
            "current_status": "RUNNING",
            "deletion_protection": false,
            "description": "",
            "desired_status": null,
            "effective_labels": {
              "goog-terraform-provisioned": "true"
            },
            "enable_display": false,
            "guest_accelerator": [],
            "hostname": "",
            "id": "projects/goblin-assistant-479511/zones/us-central1-a/instances/ollama-gpu",
            "instance_encryption_key": [],
            "instance_id": "3599859758844248361",
            "key_revocation_action_type": "",
            "label_fingerprint": "vezUS-42LLM=",
            "labels": {},
            "machine_type": "e2-standard-4",
            "metadata": {},
            "metadata_fingerprint": "BPu9sCDfw24=",
            "metadata_startup_script": "#!/usr/bin/env bash\nset -euo pipefail\n\napt-get update -y\napt-get install -y curl ca-certificates jq\n\nif ! command -v docker \u003e/dev/null 2\u003e\u00261; then\n  curl -fsSL https://get.docker.com | sh\n  systemctl enable docker\n  systemctl restart docker\nfi\n\nmkdir -p /opt/ollama\n\ncat \u003e /etc/systemd/system/ollama.service \u003c\u003c'EOF'\n[Unit]\nDescription=Ollama server (Docker)\nAfter=network-online.target docker.service\nRequires=docker.service\nWants=network-online.target\n\n[Service]\nRestart=always\nRestartSec=5\nExecStartPre=-/usr/bin/docker rm -f ollama\nExecStart=/usr/bin/docker run --name ollama --network host -v /opt/ollama:/root/.ollama ollama/ollama:latest\nExecStop=/usr/bin/docker stop ollama\n\n[Install]\nWantedBy=multi-user.target\nEOF\n\nsystemctl daemon-reload\nsystemctl enable ollama\nsystemctl restart ollama\n\n# Wait for API readiness\nfor i in $(seq 1 45); do\n  if curl -sf --max-time 2 \"http://127.0.0.1:11434/api/tags\" \u003e/dev/null 2\u003e\u00261; then\n    break\n  fi\n  sleep 2\ndone\n\n# Best-effort model warm-up (does not fail startup).\n/usr/bin/docker exec ollama ollama pull gemma:2b || true\n/usr/bin/docker exec ollama ollama pull phi3:3.8b || true\n/usr/bin/docker exec ollama ollama pull qwen2.5:3b || true\n/usr/bin/docker exec ollama ollama pull mistral:7b || true\n",
            "min_cpu_platform": "",
            "name": "ollama-gpu",
            "network_interface": [
              {
                "access_config": [
                  {
                    "nat_ip": "34.59.191.226",
                    "network_tier": "PREMIUM",
                    "public_ptr_domain_name": ""
                  }
                ],
                "alias_ip_range": [],
                "igmp_query": "",
                "internal_ipv6_prefix_length": 0,
                "ipv6_access_config": [],
                "ipv6_access_type": "",
                "ipv6_address": "",
                "name": "nic0",
                "network": "https://www.googleapis.com/compute/v1/projects/goblin-assistant-479511/global/networks/llm-net",
                "network_attachment": "",
                "network_ip": "10.70.0.5",
                "nic_type": "",
                "parent_nic_name": "",
                "queue_count": 0,
                "stack_type": "IPV4_ONLY",
                "subnetwork": "https://www.googleapis.com/compute/v1/projects/goblin-assistant-479511/regions/us-central1/subnetworks/llm-subnet",
                "subnetwork_project": "goblin-assistant-479511",
                "vlan": 0
              }
            ],
            "network_performance_config": [],
            "params": [],
            "project": "goblin-assistant-479511",
            "reservation_affinity": [],
            "resource_policies": [],
            "scheduling": [
              {
                "automatic_restart": true,
                "availability_domain": 0,
                "instance_termination_action": "",
                "local_ssd_recovery_timeout": [],
                "max_run_duration": [],
                "min_node_cpus": 0,
                "node_affinities": [],
                "on_host_maintenance": "MIGRATE",
                "on_instance_stop_action": [],
                "preemptible": false,
                "provisioning_model": "STANDARD",
                "termination_time": ""
              }
            ],
            "scratch_disk": [],
            "self_link": "https://www.googleapis.com/compute/v1/projects/goblin-assistant-479511/zones/us-central1-a/instances/ollama-gpu",
            "service_account": [
              {
                "email": "llm-runtime@goblin-assistant-479511.iam.gserviceaccount.com",
                "scopes": [
                  "https://www.googleapis.com/auth/cloud-platform"
                ]
              }
            ],
            "shielded_instance_config": [
              {
                "enable_integrity_monitoring": true,
                "enable_secure_boot": false,
                "enable_vtpm": true
              }
            ],
            "tags": [
              "ollama-gpu"
            ],
            "tags_fingerprint": "MXwVM6fXpeo=",
            "terraform_labels": {
              "goog-terraform-provisioned": "true"
            },
            "timeouts": null,
            "zone": "us-central1-a"
          },
          "sensitive_attributes": [],
          "private": "eyJlMmJmYjczMC1lY2FhLTExZTYtOGY4OC0zNDM2M2JjN2M0YzAiOnsiY3JlYXRlIjoxMjAwMDAwMDAwMDAwLCJkZWxldGUiOjEyMDAwMDAwMDAwMDAsInVwZGF0ZSI6MTIwMDAwMDAwMDAwMH0sInNjaGVtYV92ZXJzaW9uIjoiNiJ9",
          "dependencies": [
            "google_compute_address.ollama_static",
            "google_compute_network.llm",
            "google_compute_subnetwork.llm",
            "google_service_account.llm"
          ]
        }
      ]
    },
    {
      "mode": "managed",
      "type": "google_compute_network",
      "name": "llm",
      "provider": "provider[\"registry.terraform.io/hashicorp/google\"]",
      "instances": [
        {
          "index_key": 0,
          "schema_version": 0,
          "attributes": {
            "auto_create_subnetworks": false,
            "bgp_always_compare_med": false,
            "bgp_best_path_selection_mode": "LEGACY",
            "bgp_inter_region_cost": "",
            "delete_bgp_always_compare_med": false,
            "delete_default_routes_on_create": false,
            "description": "",
            "enable_ula_internal_ipv6": false,
            "gateway_ipv4": "",
            "id": "projects/goblin-assistant-479511/global/networks/llm-net",
            "internal_ipv6_range": "",
            "mtu": 0,
            "name": "llm-net",
            "network_firewall_policy_enforcement_order": "AFTER_CLASSIC_FIREWALL",
            "network_id": "3529770595562719662",
            "network_profile": "",
            "numeric_id": "3529770595562719662",
            "params": [],
            "project": "goblin-assistant-479511",
            "routing_mode": "REGIONAL",
            "self_link": "https://www.googleapis.com/compute/v1/projects/goblin-assistant-479511/global/networks/llm-net",
            "timeouts": null
          },
          "sensitive_attributes": [],
          "private": "eyJlMmJmYjczMC1lY2FhLTExZTYtOGY4OC0zNDM2M2JjN2M0YzAiOnsiY3JlYXRlIjoxMjAwMDAwMDAwMDAwLCJkZWxldGUiOjEyMDAwMDAwMDAwMDAsInVwZGF0ZSI6MTIwMDAwMDAwMDAwMH19"
        }
      ]
    },
    {
      "mode": "managed",
      "type": "google_compute_subnetwork",
      "name": "llm",
      "provider": "provider[\"registry.terraform.io/hashicorp/google\"]",
      "instances": [
        {
          "index_key": 0,
          "schema_version": 0,
          "attributes": {
            "creation_timestamp": "2026-02-13T06:38:14.902-08:00",
            "description": "",
            "external_ipv6_prefix": "",
            "fingerprint": null,
            "gateway_address": "10.70.0.1",
            "id": "projects/goblin-assistant-479511/regions/us-central1/subnetworks/llm-subnet",
            "internal_ipv6_prefix": "",
            "ip_cidr_range": "10.70.0.0/20",
            "ip_collection": null,
            "ipv6_access_type": "",
            "ipv6_cidr_range": "",
            "ipv6_gce_endpoint": "",
            "log_config": [],
            "name": "llm-subnet",
            "network": "https://www.googleapis.com/compute/v1/projects/goblin-assistant-479511/global/networks/llm-net",
            "params": [],
            "private_ip_google_access": false,
            "private_ipv6_google_access": "DISABLE_GOOGLE_ACCESS",
            "project": "goblin-assistant-479511",
            "purpose": "PRIVATE",
            "region": "us-central1",
            "reserved_internal_range": "",
            "role": "",
            "secondary_ip_range": [],
            "self_link": "https://www.googleapis.com/compute/v1/projects/goblin-assistant-479511/regions/us-central1/subnetworks/llm-subnet",
            "send_secondary_ip_range_if_empty": null,
            "stack_type": "IPV4_ONLY",
            "state": "",
            "subnetwork_id": 952030936464263609,
            "timeouts": null
          },
          "sensitive_attributes": [],
          "private": "eyJlMmJmYjczMC1lY2FhLTExZTYtOGY4OC0zNDM2M2JjN2M0YzAiOnsiY3JlYXRlIjoxMjAwMDAwMDAwMDAwLCJkZWxldGUiOjEyMDAwMDAwMDAwMDAsInVwZGF0ZSI6MTIwMDAwMDAwMDAwMH19",
          "dependencies": [
            "google_compute_network.llm"
          ]
        }
      ]
    },
    {
      "mode": "managed",
      "type": "google_service_account",
      "name": "llm",
      "provider": "provider[\"registry.terraform.io/hashicorp/google\"]",
      "instances": [
        {
          "index_key": 0,
          "schema_version": 0,
          "attributes": {
            "account_id": "llm-runtime",
            "create_ignore_already_exists": null,
            "description": "",
            "disabled": false,
            "display_name": "LLM runtime service account",
            "email": "llm-runtime@goblin-assistant-479511.iam.gserviceaccount.com",
            "id": "projects/goblin-assistant-479511/serviceAccounts/llm-runtime@goblin-assistant-479511.iam.gserviceaccount.com",
            "member": "serviceAccount:llm-runtime@goblin-assistant-479511.iam.gserviceaccount.com",
            "name": "projects/goblin-assistant-479511/serviceAccounts/llm-runtime@goblin-assistant-479511.iam.gserviceaccount.com",
            "project": "goblin-assistant-479511",
            "timeouts": null,
            "unique_id": "110948716614675131678"
          },
          "sensitive_attributes": [],
          "private": "eyJlMmJmYjczMC1lY2FhLTExZTYtOGY4OC0zNDM2M2JjN2M0YzAiOnsiY3JlYXRlIjozMDAwMDAwMDAwMDB9fQ=="
        }
      ]
    }
  ],
  "check_results": [
    {
      "object_kind": "resource",
      "config_addr": "google_compute_firewall.ollama_allow",
      "status": "pass",
      "objects": [
        {
          "object_addr": "google_compute_firewall.ollama_allow[0]",
          "status": "pass"
        }
      ]
    },
    {
      "object_kind": "resource",
      "config_addr": "google_compute_firewall.llamacpp_allow",
      "status": "pass",
      "objects": [
        {
          "object_addr": "google_compute_firewall.llamacpp_allow[0]",
          "status": "pass"
        }
      ]
    }
  ]
}
