---
title: ForgeTM
type: reference
project: ForgeTM
status: draft
owner: ForgeTM
---

**AI Trading & Market Analysis Platform** - FastAPI backend with unified LLM API + React/TypeScript frontend application.

## ğŸ›ï¸ Architecture

A modern full-stack AI platform with:

- âš¡ **Backend**: FastAPI (Python) - Unified LLM API proxy supporting OpenAI, Gemini, and DeepSeek
- ğŸ¨ **Frontend**: React + TypeScript + Vite - Modern trading dashboard
- ğŸ¤– **AI Integration**: LiteLLM proxy for multi-provider LLM access
- ğŸ“Š **Features**: Real-time market data, algorithmic trading, AI-powered analysis

## ğŸ“ Project Structure

```text
ForgeTM/
â”œâ”€â”€ ğŸ“‚ apps/
â”‚   â”œâ”€â”€ ğŸ backend/src/     # FastAPI application with LiteLLM integration
â”‚   â”‚   â”œâ”€â”€ forge/
â”‚   â”‚   â”‚   â”œâ”€â”€ api/litellm.py    # LLM proxy endpoints
â”‚   â”‚   â”‚   â”œâ”€â”€ api/health.py     # Health monitoring
â”‚   â”‚   â”‚   â””â”€â”€ main.py           # FastAPI app setup
â”‚   â””â”€â”€ ğŸ¨ frontend/        # React + TypeScript SPA
â”œâ”€â”€ âš™ï¸ .vscode/            # Project-specific tasks and settings
â””â”€â”€ ğŸ”§ .env.example        # Environment configuration
```

## ğŸš€ Quick Setup

### Prerequisites

- Python 3.11+
- Node.js 18+
- API keys for AI providers (OpenAI, Gemini, DeepSeek)

### Backend Setup

```bash
# ğŸ Create Python virtual environment
cd ForgeTM/apps/backend
python -m venv .venv
source .venv/bin/activate

# ğŸ“¦ Install dependencies
pip install -r requirements.txt

# ğŸ”‘ Configure API keys
cp .env.example .env
# Edit .env with your actual API keys (see API_KEYS_MANAGEMENT.md)
```

### Frontend Setup

```bash
# ğŸ“¦ Install Node.js dependencies
cd ForgeTM/apps/frontend
pnpm install
```

## â–¶ï¸ Running the Application

Use VS Code tasks or run manually:

### Backend Server

```bash
# âš¡ Start FastAPI server
cd ForgeTM/apps/backend
source .venv/bin/activate
uvicorn forge.main:app --reload --host 127.0.0.1 --port 8000
```

### Frontend Development

```bash
# ğŸ¨ Start development server
cd ForgeTM/apps/frontend
pnpm dev
```

## ğŸ§ª Development

### Testing

```bash
# Backend tests
cd ForgeTM/apps/backend
source .venv/bin/activate
pytest

# Frontend tests
cd ForgeTM/apps/frontend
pnpm test
```

### Linting

```bash
# ğŸ” Lint all code
cd ForgeTM
# Use VS Code tasks or run from root
```

## ğŸ”— API Documentation

Once running, visit:

- ğŸ“– **API Docs**: `http://localhost:8000/docs` (Swagger UI)
- ğŸ”„ **Alternative Docs**: `http://localhost:8000/redoc`
- ğŸ“‹ **API Guide**: `Obsidian/api-guide.md`

### Key Endpoints

- `GET /health` - Service health status
- `GET /v1/models` - List available LLM models
- `POST /v1/chat/completions` - Unified chat completions (OpenAI-compatible)
- `GET /v1/providers` - Provider configuration status

## ğŸ¤– AI Providers

The backend integrates with multiple LLM providers through LiteLLM:

- **OpenAI**: GPT-3.5-turbo, GPT-4, GPT-4-turbo
- **Google Gemini**: Gemini Pro, Gemini Pro Vision
- **DeepSeek**: DeepSeek Chat, DeepSeek Coder

### API Key Setup

Configure API keys in `apps/backend/.env`:

```bash
OPENAI_API_KEY=sk-proj-...
GEMINI_API_KEY=AIzaSy...
DEEPSEEK_API_KEY=sk-...
```

See `Obsidian/API_KEYS_MANAGEMENT.md` for detailed key management instructions.
