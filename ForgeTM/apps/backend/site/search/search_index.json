{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"ForgeTM Backend","text":"<p>Welcome to the ForgeTM Backend documentation. This is a production-ready FastAPI-based backend service that provides AI model management and orchestration capabilities.</p>"},{"location":"#overview","title":"Overview","text":"<p>ForgeTM Backend is designed to be a robust, observable, and scalable API service that integrates with multiple AI providers including Ollama for local models and LiteLLM for unified access to cloud-based LLMs.</p>"},{"location":"#key-features","title":"Key Features","text":"<ul> <li>Multi-Provider Support: Seamless integration with Ollama and LiteLLM</li> <li>Observability: OpenTelemetry tracing and Sentry error tracking</li> <li>Background Processing: Celery-based task queue with Redis backend</li> <li>Security: Container security scanning and secret management</li> <li>Developer Experience: Comprehensive testing, linting, and documentation</li> </ul>"},{"location":"#quick-start","title":"Quick Start","text":""},{"location":"#prerequisites","title":"Prerequisites","text":"<ul> <li>Python 3.11+</li> <li>Docker and Docker Compose</li> <li>uv package manager</li> <li>Ollama (optional, for local models)</li> </ul>"},{"location":"#installation","title":"Installation","text":"<pre><code># Clone the repository\ngit clone &lt;repository-url&gt;\ncd ForgeMonorepo/ForgeTM/apps/backend\n\n# Install dependencies\nuv sync\n\n# Copy environment file\ncp .env.example .env\n\n# Run the application\nuvicorn forge.main:app --reload\n</code></pre>"},{"location":"#docker-development","title":"Docker Development","text":"<pre><code># Start all services\ndocker-compose up -d\n\n# View logs\ndocker-compose logs -f backend\n</code></pre>"},{"location":"#api-documentation","title":"API Documentation","text":"<ul> <li>Interactive API Docs (Swagger UI) - When running locally</li> <li>ReDoc - Alternative API documentation</li> <li>OpenAPI Schema - JSON schema for integration</li> </ul>"},{"location":"#architecture","title":"Architecture","text":""},{"location":"#core-components","title":"Core Components","text":"<ul> <li>FastAPI Application: Main web framework with automatic OpenAPI generation</li> <li>Provider APIs: Modular routers for different AI providers</li> <li>Configuration Management: Pydantic Settings with environment variable support</li> <li>Observability Stack: OpenTelemetry + Jaeger for tracing, Sentry for error tracking</li> <li>Background Tasks: Celery with Redis for asynchronous processing</li> </ul>"},{"location":"#data-flow","title":"Data Flow","text":"<pre><code>Client Request \u2192 FastAPI \u2192 Provider Router \u2192 External API\n                      \u2193\n               Observability (Tracing, Metrics)\n                      \u2193\n               Background Tasks (if needed)\n</code></pre>"},{"location":"#development","title":"Development","text":""},{"location":"#project-structure","title":"Project Structure","text":"<pre><code>src/forge/\n\u251c\u2500\u2500 main.py              # FastAPI application\n\u251c\u2500\u2500 config.py            # Settings and configuration\n\u251c\u2500\u2500 api/                 # API routers\n\u2502   \u251c\u2500\u2500 providers.py     # Provider health checks\n\u2502   \u2514\u2500\u2500 ollama.py        # Ollama model management\n\u251c\u2500\u2500 observability/       # Monitoring and tracing\n\u2502   \u251c\u2500\u2500 tracing.py       # OpenTelemetry setup\n\u2502   \u2514\u2500\u2500 sentry.py        # Error tracking\n\u251c\u2500\u2500 tasks.py             # Background tasks\n\u2514\u2500\u2500 celery_app.py        # Celery configuration\n</code></pre>"},{"location":"#testing","title":"Testing","text":"<pre><code># Run all tests\npytest\n\n# Run with coverage\npytest --cov=forge --cov-report=html\n\n# Run specific test file\npytest tests/test_tasks.py\n</code></pre>"},{"location":"#code-quality","title":"Code Quality","text":"<pre><code># Linting and formatting\nruff check .\nruff format .\n\n# Type checking\nmypy src/\n</code></pre>"},{"location":"#deployment","title":"Deployment","text":""},{"location":"#production-checklist","title":"Production Checklist","text":"<ul> <li> Environment variables configured</li> <li> Secrets encrypted with SOPS</li> <li> Database migrations applied</li> <li> Health checks passing</li> <li> Monitoring configured</li> <li> SSL certificates installed</li> </ul>"},{"location":"#docker-production","title":"Docker Production","text":"<pre><code># Build production image\ndocker build -t forge-backend:latest .\n\n# Run with production compose\ndocker-compose -f docker-compose.prod.yml up -d\n</code></pre>"},{"location":"#configuration","title":"Configuration","text":""},{"location":"#environment-variables","title":"Environment Variables","text":"Variable Description Default <code>OLLAMA_BASE_URL</code> Ollama API endpoint <code>http://localhost:11434</code> <code>LITELLM_PROXY_URL</code> LiteLLM proxy endpoint <code>http://localhost:4000</code> <code>REDIS_URL</code> Redis connection URL <code>redis://localhost:6379/0</code> <code>ENABLE_TRACING</code> Enable OpenTelemetry tracing <code>false</code> <code>SENTRY_DSN</code> Sentry DSN for error tracking - <p>See <code>.env.example</code> for complete configuration options.</p>"},{"location":"#monitoring","title":"Monitoring","text":""},{"location":"#health-endpoints","title":"Health Endpoints","text":"<ul> <li><code>GET /health</code> - Basic application health</li> <li><code>GET /providers/health</code> - Provider-specific health checks</li> </ul>"},{"location":"#tracing","title":"Tracing","text":"<p>Traces are exported to Jaeger at <code>http://localhost:16686</code> when tracing is enabled.</p>"},{"location":"#error-tracking","title":"Error Tracking","text":"<p>Errors are automatically captured and sent to Sentry for analysis and alerting.</p>"},{"location":"#contributing","title":"Contributing","text":"<ol> <li>Fork the repository</li> <li>Create a feature branch</li> <li>Make your changes</li> <li>Add tests for new functionality</li> <li>Ensure all tests pass</li> <li>Submit a pull request</li> </ol>"},{"location":"#license","title":"License","text":"<p>This project is licensed under the MIT License - see the LICENSE file for details.&gt;</p>"},{"location":"api-guide/","title":"API Guide","text":"<p>This guide explains how to use the ForgeTM Backend API for AI model management and orchestration.</p>"},{"location":"api-guide/#overview","title":"Overview","text":"<p>The ForgeTM Backend provides RESTful APIs for:</p> <ul> <li>Provider Management: Health checks and status monitoring for AI providers</li> <li>Model Management: Listing, pulling, and managing Ollama models</li> <li>Health Monitoring: System and provider health status</li> <li>Background Tasks: Asynchronous processing capabilities</li> </ul>"},{"location":"api-guide/#base-url","title":"Base URL","text":"<p>All API endpoints are relative to the base URL of your ForgeTM Backend instance:</p> <ul> <li>Development: <code>http://localhost:8000</code></li> <li>Production: Your deployed instance URL</li> </ul>"},{"location":"api-guide/#authentication","title":"Authentication","text":"<p>Currently, the API does not require authentication. In production deployments, consider adding authentication middleware.</p>"},{"location":"api-guide/#endpoints","title":"Endpoints","text":""},{"location":"api-guide/#health-endpoints","title":"Health Endpoints","text":""},{"location":"api-guide/#get-health","title":"GET /health","text":"<p>Returns basic application health information.</p> <p>Response:</p> <pre><code>{\n  \"status\": \"ok\",\n  \"version\": \"0.1.0\",\n  \"uptime_sec\": 123.456\n}\n</code></pre>"},{"location":"api-guide/#get-providershealth","title":"GET /providers/health","text":"<p>Returns health status for all configured AI providers.</p> <p>Response:</p> <pre><code>{\n  \"status\": \"ok\",\n  \"took_ms\": 150,\n  \"providers\": {\n    \"ollama\": {\n      \"name\": \"ollama\",\n      \"ok\": true,\n      \"latency_ms\": 45,\n      \"url\": \"http://localhost:11434\"\n    },\n    \"litellm\": {\n      \"name\": \"litellm\",\n      \"ok\": true,\n      \"latency_ms\": 105,\n      \"url\": \"http://localhost:4000\"\n    }\n  }\n}\n</code></pre>"},{"location":"api-guide/#ollama-endpoints","title":"Ollama Endpoints","text":""},{"location":"api-guide/#get-ollamamodels","title":"GET /ollama/models","text":"<p>Lists all installed Ollama models.</p> <p>Response:</p> <pre><code>[\n  {\n    \"name\": \"llama2:7b\",\n    \"size\": 3791737152,\n    \"digest\": \"sha256:123...\"\n  }\n]\n</code></pre>"},{"location":"api-guide/#post-ollamapull","title":"POST /ollama/pull","text":"<p>Pulls (downloads) a model from the Ollama registry.</p> <p>Request Body:</p> <pre><code>{\n  \"model\": \"llama2:7b\",\n  \"stream\": false\n}\n</code></pre> <p>Response:</p> <pre><code>{\n  \"status\": \"success\",\n  \"digest\": \"sha256:123...\",\n  \"total\": 3791737152,\n  \"completed\": 3791737152\n}\n</code></pre>"},{"location":"api-guide/#error-handling","title":"Error Handling","text":"<p>The API uses standard HTTP status codes:</p> <ul> <li>200: Success</li> <li>400: Bad Request (invalid parameters)</li> <li>404: Not Found</li> <li>500: Internal Server Error</li> <li>502: Bad Gateway (external service error)</li> </ul> <p>Error responses include a <code>detail</code> field with more information:</p> <pre><code>{\n  \"detail\": \"Ollama returned 404\"\n}\n</code></pre>"},{"location":"api-guide/#rate-limiting","title":"Rate Limiting","text":"<p>Currently, there are no rate limits implemented. Consider adding rate limiting for production use.</p>"},{"location":"api-guide/#examples","title":"Examples","text":""},{"location":"api-guide/#python-client","title":"Python Client","text":"<pre><code>import httpx\n\n# Health check\nresponse = httpx.get(\"http://localhost:8000/health\")\nprint(response.json())\n\n# List Ollama models\nresponse = httpx.get(\"http://localhost:8000/ollama/models\")\nmodels = response.json()\nprint(f\"Available models: {[m['name'] for m in models]}\")\n\n# Pull a model\nresponse = httpx.post(\n    \"http://localhost:8000/ollama/pull\",\n    json={\"model\": \"llama2:7b\", \"stream\": False}\n)\nprint(response.json())\n</code></pre>"},{"location":"api-guide/#javascript-client","title":"JavaScript Client","text":"<pre><code>// Health check\nconst health = await fetch('http://localhost:8000/health');\nconst healthData = await health.json();\nconsole.log(healthData);\n\n// List models\nconst models = await fetch('http://localhost:8000/ollama/models');\nconst modelsData = await models.json();\nconsole.log('Available models:', modelsData.map(m =&gt; m.name));\n\n// Pull model\nconst pullResponse = await fetch('http://localhost:8000/ollama/pull', {\n  method: 'POST',\n  headers: { 'Content-Type': 'application/json' },\n  body: JSON.stringify({ model: 'llama2:7b', stream: false })\n});\nconst pullData = await pullResponse.json();\nconsole.log(pullData);\n</code></pre>"},{"location":"api-guide/#webhooks-and-callbacks","title":"Webhooks and Callbacks","text":"<p>The API currently does not support webhooks. Background tasks complete asynchronously without callbacks.</p>"},{"location":"api-guide/#sdks-and-libraries","title":"SDKs and Libraries","text":"<p>Official SDKs are not yet available. Use standard HTTP clients or the OpenAPI-generated client libraries.</p>"},{"location":"api-guide/#troubleshooting","title":"Troubleshooting","text":""},{"location":"api-guide/#common-issues","title":"Common Issues","text":"<ol> <li>Connection Refused: Ensure the backend service is running</li> <li>Provider Unavailable: Check that Ollama/LiteLLM services are accessible</li> <li>Model Not Found: Verify the model name and that it's available in Ollama</li> </ol>"},{"location":"api-guide/#debugging","title":"Debugging","text":"<p>Enable debug logging by setting the environment variable:</p> <pre><code>export LOG_LEVEL=DEBUG\n</code></pre> <p>Check the application logs for detailed error information.</p>"},{"location":"background-tasks/","title":"Background Tasks","text":"<p>This guide covers the background task system in ForgeTM Backend, built on Celery with Redis.</p>"},{"location":"background-tasks/#overview","title":"Overview","text":"<p>ForgeTM Backend uses Celery for asynchronous task processing, enabling:</p> <ul> <li>Non-blocking operations: Long-running tasks don't block API responses</li> <li>Reliability: Tasks survive application restarts</li> <li>Monitoring: Built-in task tracking and error handling</li> <li>Scalability: Multiple worker processes for high throughput</li> </ul>"},{"location":"background-tasks/#architecture","title":"Architecture","text":""},{"location":"background-tasks/#components","title":"Components","text":"<ul> <li>Celery App: Task registry and configuration (<code>celery_app.py</code>)</li> <li>Task Definitions: Business logic tasks (<code>tasks.py</code>)</li> <li>Worker Process: Task execution engine (<code>celery_worker.py</code>)</li> <li>Result Backend: Task result storage (Redis)</li> <li>Message Broker: Task queuing (Redis)</li> </ul>"},{"location":"background-tasks/#data-flow","title":"Data Flow","text":"<pre><code>graph LR\n    A[API Request] --&gt; B[FastAPI Route]\n    B --&gt; C[Task.delay()]\n    C --&gt; D[Redis Queue]\n    D --&gt; E[Worker]\n    E --&gt; F[Result Backend]\n    F --&gt; G[Response]\n</code></pre>"},{"location":"background-tasks/#configuration","title":"Configuration","text":""},{"location":"background-tasks/#celery-app-setup","title":"Celery App Setup","text":"<pre><code># src/forge/celery_app.py\nfrom celery import Celery\nfrom celery.signals import task_prerun, task_postrun, task_success, task_failure, task_retry\n\napp = Celery('forge')\napp.conf.update(\n    broker_url=settings.redis_url,\n    result_backend=settings.redis_url,\n    task_serializer='json',\n    accept_content=['json'],\n    result_serializer='json',\n    timezone='UTC',\n    enable_utc=True,\n)\n\n# Signal handlers for monitoring\n@task_prerun.connect\ndef task_prerun_handler(sender, task_id, task, args, kwargs, **extra):\n    logger.info(f\"Task {task.name} started\", extra={\n        'task_id': task_id,\n        'task_name': task.name,\n        'args': args,\n        'kwargs': kwargs\n    })\n\n@task_success.connect\ndef task_success_handler(sender, result, **kwargs):\n    logger.info(f\"Task {sender.name} completed successfully\")\n\n@task_failure.connect\ndef task_failure_handler(sender, exception, traceback, **kwargs):\n    logger.error(f\"Task {sender.name} failed: {exception}\")\n    # Send to Sentry\n    capture_exception(exception, task_name=sender.name)\n</code></pre>"},{"location":"background-tasks/#task-definitions","title":"Task Definitions","text":"<pre><code># src/forge/tasks.py\nfrom forge.celery_app import app\nfrom forge.observability.tracing import get_tracer\n\ntracer = get_tracer(__name__)\n\n@app.task(bind=True, name='health_check')\ndef health_check_task(self):\n    \"\"\"Perform comprehensive health checks.\"\"\"\n    with tracer.start_as_current_span('health_check_task') as span:\n        span.set_attribute('task.type', 'health_check')\n\n        try:\n            # Check Redis connectivity\n            redis_ok = check_redis()\n\n            # Check external services\n            ollama_ok = check_ollama_health()\n            litellm_ok = check_litellm_health()\n\n            result = {\n                'status': 'ok' if all([redis_ok, ollama_ok, litellm_ok]) else 'degraded',\n                'timestamp': datetime.utcnow().isoformat(),\n                'checks': {\n                    'redis': redis_ok,\n                    'ollama': ollama_ok,\n                    'litellm': litellm_ok\n                }\n            }\n\n            span.set_attribute('health.overall_status', result['status'])\n            return result\n\n        except Exception as e:\n            span.set_attribute('error', True)\n            span.set_attribute('error.message', str(e))\n            raise self.retry(countdown=60, exc=e)\n</code></pre>"},{"location":"background-tasks/#task-types","title":"Task Types","text":""},{"location":"background-tasks/#health-check-task","title":"Health Check Task","text":"<pre><code>@app.task(name='health_check')\ndef health_check_task():\n    \"\"\"Regular health monitoring of all dependencies.\"\"\"\n    return {\n        'redis': check_redis_connection(),\n        'ollama': check_ollama_service(),\n        'litellm': check_litellm_service(),\n        'timestamp': datetime.utcnow().isoformat()\n    }\n</code></pre> <p>Usage:</p> <pre><code>from forge.tasks import health_check_task\n\n# Fire and forget\nhealth_check_task.delay()\n\n# Wait for result\nresult = health_check_task.delay().get(timeout=30)\n</code></pre>"},{"location":"background-tasks/#cleanup-task","title":"Cleanup Task","text":"<pre><code>@app.task(name='cleanup_expired_data')\ndef cleanup_expired_data_task():\n    \"\"\"Clean up expired cache entries and temporary data.\"\"\"\n    with tracer.start_as_current_span('cleanup_task') as span:\n        # Clean Redis expired keys\n        cleaned_keys = redis_client.delete(*expired_keys)\n\n        # Clean temporary files\n        temp_files_removed = clean_temp_directory()\n\n        span.set_attribute('cleanup.redis_keys', cleaned_keys)\n        span.set_attribute('cleanup.temp_files', temp_files_removed)\n\n        return {\n            'redis_keys_cleaned': cleaned_keys,\n            'temp_files_removed': temp_files_removed\n        }\n</code></pre>"},{"location":"background-tasks/#model-cache-refresh-task","title":"Model Cache Refresh Task","text":"<pre><code>@app.task(name='model_cache_refresh')\ndef model_cache_refresh_task():\n    \"\"\"Refresh cached model information from providers.\"\"\"\n    with tracer.start_as_current_span('cache_refresh') as span:\n        # Update Ollama model cache\n        ollama_models = fetch_ollama_models()\n        cache.set('ollama_models', ollama_models, ttl=3600)\n\n        # Update LiteLLM model cache\n        litellm_models = fetch_litellm_models()\n        cache.set('litellm_models', litellm_models, ttl=3600)\n\n        span.set_attribute('cache.models_cached', len(ollama_models) + len(litellm_models))\n\n        return {\n            'ollama_models': len(ollama_models),\n            'litellm_models': len(litellm_models),\n            'cached_at': datetime.utcnow().isoformat()\n        }\n</code></pre>"},{"location":"background-tasks/#notification-task","title":"Notification Task","text":"<pre><code>@app.task(name='send_notification', bind=True)\ndef send_notification_task(self, user_id: str, message: str, channel: str = 'email'):\n    \"\"\"Send notifications to users.\"\"\"\n    with tracer.start_as_current_span('send_notification') as span:\n        span.set_attribute('notification.user_id', user_id)\n        span.set_attribute('notification.channel', channel)\n\n        try:\n            if channel == 'email':\n                send_email(user_id, message)\n            elif channel == 'webhook':\n                send_webhook(user_id, message)\n            else:\n                raise ValueError(f\"Unsupported channel: {channel}\")\n\n            span.set_attribute('notification.success', True)\n            return {'status': 'sent', 'channel': channel}\n\n        except Exception as e:\n            span.set_attribute('notification.success', False)\n            span.set_attribute('error.message', str(e))\n\n            # Retry with exponential backoff\n            raise self.retry(countdown=min(300, 2 ** self.request.retries), exc=e)\n</code></pre>"},{"location":"background-tasks/#analytics-aggregation-task","title":"Analytics Aggregation Task","text":"<pre><code>@app.task(name='analytics_aggregation')\ndef analytics_aggregation_task():\n    \"\"\"Aggregate usage analytics for reporting.\"\"\"\n    with tracer.start_as_current_span('analytics_aggregation') as span:\n        # Aggregate request metrics\n        request_stats = aggregate_request_metrics()\n\n        # Aggregate model usage\n        model_stats = aggregate_model_usage()\n\n        # Store aggregated data\n        store_analytics_data(request_stats, model_stats)\n\n        span.set_attribute('analytics.requests_processed', request_stats['total'])\n        span.set_attribute('analytics.models_used', len(model_stats))\n\n        return {\n            'requests': request_stats,\n            'models': model_stats,\n            'aggregated_at': datetime.utcnow().isoformat()\n        }\n</code></pre>"},{"location":"background-tasks/#running-workers","title":"Running Workers","text":""},{"location":"background-tasks/#development","title":"Development","text":"<pre><code># Start worker with info logging\nuv run celery worker -A forge.celery_app --loglevel=info\n\n# Start worker with beat scheduler\nuv run celery worker -A forge.celery_app --loglevel=info --beat\n\n# Start multiple workers\nuv run celery worker -A forge.celery_app --loglevel=info --concurrency=4\n</code></pre>"},{"location":"background-tasks/#production","title":"Production","text":"<pre><code># Using the worker script\nuv run python celery_worker.py\n\n# Or directly\ncelery worker -A forge.celery_app --loglevel=warning --concurrency=8\n</code></pre>"},{"location":"background-tasks/#worker-script","title":"Worker Script","text":"<pre><code># celery_worker.py\n#!/usr/bin/env python3\nimport os\nimport signal\nimport sys\nfrom forge.celery_app import app\nfrom forge.config import settings\n\n\ndef start_worker():\n    \"\"\"Start Celery worker with proper configuration.\"\"\"\n    worker = app.Worker(\n        loglevel=settings.log_level.lower(),\n        concurrency=settings.celery_concurrency,\n        hostname=f'forge-worker@{settings.app_env}',\n    )\n    worker.start()\n\n\ndef start_beat():\n    \"\"\"Start Celery beat scheduler.\"\"\"\n    beat = app.Beat(\n        loglevel=settings.log_level.lower(),\n        hostname=f'forge-beat@{settings.app_env}',\n    )\n    beat.start()\n\n\ndef check_health():\n    \"\"\"Check worker health.\"\"\"\n    inspect = app.control.inspect()\n    active = inspect.active()\n    stats = inspect.stats()\n\n    return {\n        'active_tasks': active,\n        'worker_stats': stats,\n        'timestamp': datetime.utcnow().isoformat()\n    }\n\n\nif __name__ == '__main__':\n    if len(sys.argv) &gt; 1 and sys.argv[1] == 'beat':\n        start_beat()\n    elif len(sys.argv) &gt; 1 and sys.argv[1] == 'health':\n        import json\n        print(json.dumps(check_health()))\n    else:\n        start_worker()\n</code></pre>"},{"location":"background-tasks/#monitoring-tasks","title":"Monitoring Tasks","text":""},{"location":"background-tasks/#task-states","title":"Task States","text":"<ul> <li>PENDING: Task waiting in queue</li> <li>STARTED: Task being processed</li> <li>RETRY: Task failed and scheduled for retry</li> <li>FAILURE: Task failed permanently</li> <li>SUCCESS: Task completed successfully</li> </ul>"},{"location":"background-tasks/#monitoring-commands","title":"Monitoring Commands","text":"<pre><code># Check active tasks\ncelery inspect active\n\n# Check registered tasks\ncelery inspect registered\n\n# Check worker stats\ncelery inspect stats\n\n# Check queue length\ncelery inspect active_queues\n</code></pre>"},{"location":"background-tasks/#flower-dashboard","title":"Flower Dashboard","text":"<pre><code># Install Flower\npip install flower\n\n# Start dashboard\ncelery flower -A forge.celery_app --address=127.0.0.1 --port=5555\n\n# Open http://localhost:5555\n</code></pre>"},{"location":"background-tasks/#error-handling","title":"Error Handling","text":""},{"location":"background-tasks/#automatic-retries","title":"Automatic Retries","text":"<pre><code>@app.task(bind=True, autoretry_for=(Exception,), retry_kwargs={'max_retries': 3})\ndef unreliable_task(self):\n    \"\"\"Task that automatically retries on any exception.\"\"\"\n    try:\n        # Risky operation\n        return do_something_risky()\n    except Exception as exc:\n        logger.warning(f\"Task failed, retrying: {exc}\")\n        raise self.retry(countdown=60 * (2 ** self.request.retries))\n</code></pre>"},{"location":"background-tasks/#custom-retry-logic","title":"Custom Retry Logic","text":"<pre><code>@app.task(bind=True)\ndef smart_retry_task(self):\n    \"\"\"Task with intelligent retry logic.\"\"\"\n    try:\n        result = call_external_api()\n        return result\n    except ConnectionError as exc:\n        # Retry immediately for connection issues\n        raise self.retry(countdown=5, exc=exc)\n    except RateLimitError as exc:\n        # Exponential backoff for rate limits\n        raise self.retry(countdown=60 * (2 ** self.request.retries), exc=exc)\n    except AuthenticationError as exc:\n        # Don't retry auth failures\n        logger.error(f\"Authentication failed: {exc}\")\n        raise\n</code></pre>"},{"location":"background-tasks/#dead-letter-queue","title":"Dead Letter Queue","text":"<pre><code># Configure dead letter exchange\napp.conf.task_reject_on_worker_lost = True\napp.conf.task_acks_late = True\napp.conf.worker_prefetch_multiplier = 1\n\n# Handle task failures\n@task_failure.connect\ndef handle_task_failure(sender, task_id, exception, args, kwargs, traceback, einfo, **extra):\n    \"\"\"Handle permanent task failures.\"\"\"\n    logger.error(f\"Task {sender.name} permanently failed: {exception}\")\n\n    # Send to dead letter queue or alert\n    send_to_dead_letter_queue(task_id, sender.name, args, kwargs, str(exception))\n</code></pre>"},{"location":"background-tasks/#testing-background-tasks","title":"Testing Background Tasks","text":""},{"location":"background-tasks/#unit-testing","title":"Unit Testing","text":"<pre><code>import pytest\nfrom unittest.mock import patch, AsyncMock\nfrom forge.tasks import health_check_task\n\n\n@pytest.mark.asyncio\nclass TestHealthCheckTask:\n    \"\"\"Test health check background task.\"\"\"\n\n    @patch('forge.tasks.check_redis')\n    @patch('forge.tasks.check_ollama_health')\n    @patch('forge.tasks.check_litellm_health')\n    async def test_health_check_success(self, mock_litellm, mock_ollama, mock_redis):\n        \"\"\"Test successful health check.\"\"\"\n        # Setup mocks\n        mock_redis.return_value = True\n        mock_ollama.return_value = True\n        mock_litellm.return_value = True\n\n        # Execute task\n        result = await health_check_task()\n\n        # Assertions\n        assert result['status'] == 'ok'\n        assert result['checks']['redis'] is True\n        assert result['checks']['ollama'] is True\n        assert result['checks']['litellm'] is True\n        assert 'timestamp' in result\n</code></pre>"},{"location":"background-tasks/#integration-testing","title":"Integration Testing","text":"<pre><code>@pytest.mark.integration\nclass TestTaskIntegration:\n    \"\"\"Integration tests for background tasks.\"\"\"\n\n    async def test_task_execution_flow(self, celery_worker):\n        \"\"\"Test complete task execution flow.\"\"\"\n        # Submit task\n        result = health_check_task.delay()\n\n        # Wait for completion\n        assert result.get(timeout=30)['status'] == 'ok'\n\n        # Check task metadata\n        assert result.state == 'SUCCESS'\n        assert result.result is not None\n</code></pre>"},{"location":"background-tasks/#testing-fixtures","title":"Testing Fixtures","text":"<pre><code># conftest.py\n@pytest.fixture(scope='session')\ndef celery_config():\n    \"\"\"Configure Celery for testing.\"\"\"\n    return {\n        'broker_url': 'redis://localhost:6379/1',  # Test database\n        'result_backend': 'redis://localhost:6379/1',\n        'task_always_eager': True,  # Execute tasks synchronously\n        'task_eager_propagates': True,\n    }\n\n\n@pytest.fixture(scope='session')\ndef celery_worker(celery_config):\n    \"\"\"Start Celery worker for integration tests.\"\"\"\n    from celery.contrib.testing.worker import start_worker\n    app.conf.update(**celery_config)\n    with start_worker(app):\n        yield\n</code></pre>"},{"location":"background-tasks/#performance-considerations","title":"Performance Considerations","text":""},{"location":"background-tasks/#task-chunking","title":"Task Chunking","text":"<pre><code>@app.task\ndef process_batch_task(items, batch_size=100):\n    \"\"\"Process items in chunks to avoid memory issues.\"\"\"\n    for i in range(0, len(items), batch_size):\n        batch = items[i:i + batch_size]\n        process_batch(batch)\n        # Allow other tasks to run\n        time.sleep(0.01)\n</code></pre>"},{"location":"background-tasks/#resource-limits","title":"Resource Limits","text":"<pre><code># Limit concurrent tasks per worker\napp.conf.worker_max_tasks_per_child = 1000\n\n# Limit task execution time\n@app.task(time_limit=300, soft_time_limit=270)\ndef long_running_task():\n    \"\"\"Task with time limits.\"\"\"\n    # Task implementation\n    pass\n</code></pre>"},{"location":"background-tasks/#monitoring-performance","title":"Monitoring Performance","text":"<pre><code># Track task execution time\n@task_prerun.connect\ndef track_task_start(sender, task_id, **kwargs):\n    redis.set(f\"task:{task_id}:start\", time.time())\n\n@task_postrun.connect\ndef track_task_end(sender, task_id, **kwargs):\n    start_time = redis.get(f\"task:{task_id}:start\")\n    if start_time:\n        duration = time.time() - float(start_time)\n        # Store metrics\n        record_task_duration(sender.name, duration)\n</code></pre>"},{"location":"background-tasks/#deployment","title":"Deployment","text":""},{"location":"background-tasks/#docker-configuration","title":"Docker Configuration","text":"<pre><code># Worker container\nFROM python:3.11-slim\n\nWORKDIR /app\nCOPY requirements*.txt ./\nRUN pip install -r requirements-worker.txt\n\nCOPY . .\nCMD [\"celery\", \"worker\", \"-A\", \"forge.celery_app\", \"--loglevel=info\"]\n</code></pre>"},{"location":"background-tasks/#kubernetes-deployment","title":"Kubernetes Deployment","text":"<pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: forge-worker\nspec:\n  replicas: 3\n  template:\n    spec:\n      containers:\n      - name: worker\n        image: forge-backend:latest\n        command: [\"celery\", \"worker\", \"-A\", \"forge.celery_app\", \"--loglevel=info\"]\n        envFrom:\n        - configMapRef:\n            name: forge-config\n        - secretRef:\n            name: forge-secrets\n        resources:\n          requests:\n            memory: \"256Mi\"\n            cpu: \"100m\"\n          limits:\n            memory: \"512Mi\"\n            cpu: \"500m\"\n</code></pre>"},{"location":"background-tasks/#best-practices","title":"Best Practices","text":"<ol> <li>Idempotent Tasks: Tasks should be safe to run multiple times</li> <li>Error Handling: Always handle exceptions appropriately</li> <li>Monitoring: Monitor task success rates and execution times</li> <li>Resource Limits: Set appropriate timeouts and resource limits</li> <li>Testing: Test both success and failure scenarios</li> <li>Logging: Include sufficient context in task logs</li> <li>Retries: Use exponential backoff for retries</li> <li>Cleanup: Clean up resources after task completion</li> <li>Documentation: Document task parameters and return values</li> <li>Versioning: Consider task versioning for API compatibility</li> </ol>"},{"location":"changelog/","title":"Changelog","text":"<p>All notable changes to this project will be documented in this file.</p> <p>The format is based on Keep a Changelog, and this project adheres to Semantic Versioning.</p>"},{"location":"changelog/#unreleased","title":"[Unreleased]","text":""},{"location":"changelog/#added","title":"Added","text":"<ul> <li>Initial MkDocs documentation setup</li> <li>OpenTelemetry instrumentation for observability</li> <li>Pydantic Settings for configuration management</li> <li>SOPS + age for secret encryption</li> <li>Container security with Trivy and Cosign</li> <li>Property-based testing with Hypothesis</li> <li>90% code coverage enforcement</li> </ul>"},{"location":"changelog/#changed","title":"Changed","text":"<ul> <li>Migrated to uv for dependency management</li> <li>Updated Ruff configuration for stricter linting</li> <li>Enhanced CI/CD with CodeQL for Python analysis</li> </ul>"},{"location":"changelog/#fixed","title":"Fixed","text":"<ul> <li>Various configuration and packaging improvements</li> </ul>"},{"location":"configuration/","title":"Configuration","text":"<p>This guide explains how to configure ForgeTM Backend for different environments and use cases.</p>"},{"location":"configuration/#environment-variables","title":"Environment Variables","text":"<p>ForgeTM Backend uses environment variables for all configuration. Copy <code>.env.example</code> to <code>.env</code> and modify as needed.</p>"},{"location":"configuration/#core-settings","title":"Core Settings","text":"Variable Description Default Required <code>APP_ENV</code> Environment (development/production) <code>development</code> No <code>LOG_LEVEL</code> Logging level (DEBUG/INFO/WARNING/ERROR) <code>INFO</code> No <code>VERSION</code> Application version <code>0.1.0</code> No"},{"location":"configuration/#server-settings","title":"Server Settings","text":"Variable Description Default Required <code>HOST</code> Server host <code>127.0.0.1</code> No <code>PORT</code> Server port <code>8000</code> No <code>WORKERS</code> Number of workers (production) <code>1</code> No"},{"location":"configuration/#ai-providers","title":"AI Providers","text":""},{"location":"configuration/#ollama-configuration","title":"Ollama Configuration","text":"Variable Description Default Required <code>OLLAMA_BASE_URL</code> Ollama API endpoint <code>http://localhost:11434</code> No <code>OLLAMA_TIMEOUT</code> Request timeout in seconds <code>30</code> No"},{"location":"configuration/#litellm-configuration","title":"LiteLLM Configuration","text":"Variable Description Default Required <code>LITELLM_PROXY_URL</code> LiteLLM proxy endpoint <code>http://localhost:4000</code> No <code>LITELLM_API_KEY</code> API key for LiteLLM - No"},{"location":"configuration/#background-tasks-celery-redis","title":"Background Tasks (Celery + Redis)","text":"Variable Description Default Required <code>REDIS_URL</code> Redis connection URL <code>redis://localhost:6379/0</code> Yes* <code>CELERY_BROKER_URL</code> Celery broker URL (usually same as Redis) Same as REDIS_URL No <code>CELERY_RESULT_BACKEND</code> Celery result backend Same as REDIS_URL No <p>*Required when using background tasks</p>"},{"location":"configuration/#observability","title":"Observability","text":""},{"location":"configuration/#opentelemetry-tracing","title":"OpenTelemetry Tracing","text":"Variable Description Default Required <code>ENABLE_TRACING</code> Enable OpenTelemetry tracing <code>false</code> No <code>OTEL_SERVICE_NAME</code> Service name for traces <code>forge-backend</code> No <code>OTEL_SERVICE_VERSION</code> Service version for traces <code>0.1.0</code> No <code>OTEL_EXPORTER_OTLP_ENDPOINT</code> OTLP exporter endpoint <code>http://localhost:4318</code> No"},{"location":"configuration/#sentry-error-tracking","title":"Sentry Error Tracking","text":"Variable Description Default Required <code>SENTRY_DSN</code> Sentry DSN for error reporting - No <code>SENTRY_ENVIRONMENT</code> Environment name for Sentry Same as APP_ENV No"},{"location":"configuration/#configuration-files","title":"Configuration Files","text":""},{"location":"configuration/#envexample","title":".env.example","text":"<p>The repository includes a comprehensive <code>.env.example</code> file with all available options and documentation:</p> <pre><code># Application\nAPP_ENV=development\nLOG_LEVEL=INFO\nVERSION=0.1.0\n\n# Server\nHOST=127.0.0.1\nPORT=8000\nWORKERS=1\n\n# AI Providers\nOLLAMA_BASE_URL=http://localhost:11434\nOLLAMA_TIMEOUT=30\n\nLITELLM_PROXY_URL=http://localhost:4000\nLITELLM_API_KEY=your_litellm_api_key_here\n\n# Background Tasks\nREDIS_URL=redis://localhost:6379/0\nCELERY_BROKER_URL=redis://localhost:6379/0\nCELERY_RESULT_BACKEND=redis://localhost:6379/0\n\n# Observability\nENABLE_TRACING=false\nOTEL_SERVICE_NAME=forge-backend\nOTEL_SERVICE_VERSION=0.1.0\nOTEL_EXPORTER_OTLP_ENDPOINT=http://localhost:4318\n\nSENTRY_DSN=https://your-sentry-dsn@sentry.io/project-id\nSENTRY_ENVIRONMENT=development\n</code></pre>"},{"location":"configuration/#docker-compose-override","title":"Docker Compose Override","text":"<p>For local development, you can override settings using <code>docker-compose.override.yml</code>:</p> <pre><code>version: '3.8'\nservices:\n  backend:\n    environment:\n      - LOG_LEVEL=DEBUG\n      - ENABLE_TRACING=true\n    ports:\n      - \"8000:8000\"\n</code></pre>"},{"location":"configuration/#environment-specific-configuration","title":"Environment-Specific Configuration","text":""},{"location":"configuration/#development-environment","title":"Development Environment","text":"<pre><code># .env\nAPP_ENV=development\nLOG_LEVEL=DEBUG\nENABLE_TRACING=true\nOLLAMA_BASE_URL=http://host.docker.internal:11434  # For Docker\n</code></pre>"},{"location":"configuration/#production-environment","title":"Production Environment","text":"<pre><code># .env\nAPP_ENV=production\nLOG_LEVEL=INFO\nENABLE_TRACING=true\nSENTRY_DSN=https://your-production-dsn@sentry.io/project-id\nWORKERS=4\n</code></pre>"},{"location":"configuration/#testing-environment","title":"Testing Environment","text":"<pre><code># .env.test\nAPP_ENV=testing\nLOG_LEVEL=WARNING\nREDIS_URL=redis://localhost:6379/1  # Separate database for tests\n</code></pre>"},{"location":"configuration/#secret-management","title":"Secret Management","text":""},{"location":"configuration/#development","title":"Development","text":"<p>For local development, secrets can be stored in <code>.env</code> files (ensure <code>.env</code> is in <code>.gitignore</code>).</p>"},{"location":"configuration/#production","title":"Production","text":"<p>For production, use your platform's secret management:</p> <ul> <li>Docker Swarm: Docker secrets</li> <li>Kubernetes: Secrets and ConfigMaps</li> <li>AWS: Systems Manager Parameter Store or Secrets Manager</li> <li>Azure: Key Vault</li> <li>GCP: Secret Manager</li> </ul>"},{"location":"configuration/#sops-encryption","title":"SOPS Encryption","text":"<p>The project supports SOPS for encrypting secrets:</p> <pre><code># Encrypt secrets\nsops --encrypt --in-place secrets.yaml\n\n# Decrypt for editing\nsops secrets.yaml\n</code></pre>"},{"location":"configuration/#validation","title":"Validation","text":"<p>Configuration is validated at startup using Pydantic Settings. Invalid configurations will cause the application to fail fast with clear error messages.</p>"},{"location":"configuration/#common-validation-errors","title":"Common Validation Errors","text":"<ol> <li>Invalid URL format: Ensure URLs include protocol (http:// or https://)</li> <li>Missing required secrets: Check that all required environment variables are set</li> <li>Invalid port numbers: Ports must be integers between 1-65535</li> <li>Malformed Redis URLs: Must follow <code>redis://host:port/db</code> format</li> </ol>"},{"location":"configuration/#runtime-configuration","title":"Runtime Configuration","text":"<p>Some settings can be changed at runtime without restart:</p> <ul> <li>Log levels (via environment or API if implemented)</li> <li>Feature flags</li> <li>Provider endpoints (with caution)</li> </ul> <p>Settings requiring restart:</p> <ul> <li>Server host/port</li> <li>Worker count</li> <li>Tracing configuration</li> <li>Database connections</li> </ul>"},{"location":"configuration/#best-practices","title":"Best Practices","text":"<ol> <li>Never commit secrets to version control</li> <li>Use different secrets for each environment</li> <li>Document all environment variables in README</li> <li>Validate configuration at startup</li> <li>Use descriptive variable names and values</li> <li>Group related settings together</li> <li>Provide sensible defaults where possible</li> </ol>"},{"location":"deployment/","title":"Deployment","text":"<p>This guide covers deploying ForgeTM Backend to production environments.</p>"},{"location":"deployment/#prerequisites","title":"Prerequisites","text":"<ul> <li>Docker and Docker Compose</li> <li>Kubernetes cluster (optional, for container orchestration)</li> <li>SSL certificate (for HTTPS)</li> <li>Domain name (optional)</li> <li>Monitoring infrastructure (Jaeger, Sentry)</li> </ul>"},{"location":"deployment/#quick-start-with-docker-compose","title":"Quick Start with Docker Compose","text":""},{"location":"deployment/#1-production-docker-compose","title":"1. Production Docker Compose","text":"<p>Create <code>docker-compose.prod.yml</code>:</p> <pre><code>version: '3.8'\n\nservices:\n  backend:\n    image: forge-backend:latest\n    build:\n      context: .\n      dockerfile: Dockerfile\n    environment:\n      - APP_ENV=production\n      - LOG_LEVEL=INFO\n      - REDIS_URL=redis://redis:6379/0\n      - ENABLE_TRACING=true\n      - SENTRY_DSN=${SENTRY_DSN}\n    ports:\n      - \"8000:8000\"\n    depends_on:\n      - redis\n    restart: unless-stopped\n    healthcheck:\n      test: [\"CMD\", \"curl\", \"-f\", \"http://localhost:8000/health\"]\n      interval: 30s\n      timeout: 10s\n      retries: 3\n\n  redis:\n    image: redis:7-alpine\n    volumes:\n      - redis_data:/data\n    restart: unless-stopped\n    healthcheck:\n      test: [\"CMD\", \"redis-cli\", \"ping\"]\n      interval: 30s\n      timeout: 10s\n      retries: 3\n\nvolumes:\n  redis_data:\n</code></pre>"},{"location":"deployment/#2-environment-setup","title":"2. Environment Setup","text":"<pre><code># Create production environment file\ncp .env.example .env.prod\n\n# Edit with production values\n# SENTRY_DSN=https://your-dsn@sentry.io/project\n# REDIS_URL=redis://redis:6379/0\n</code></pre>"},{"location":"deployment/#3-deploy","title":"3. Deploy","text":"<pre><code># Build and deploy\ndocker-compose -f docker-compose.prod.yml up -d\n\n# Check status\ndocker-compose -f docker-compose.prod.yml ps\n\n# View logs\ndocker-compose -f docker-compose.prod.yml logs -f backend\n</code></pre>"},{"location":"deployment/#kubernetes-deployment","title":"Kubernetes Deployment","text":""},{"location":"deployment/#1-namespace","title":"1. Namespace","text":"<pre><code>kubectl create namespace forge\n</code></pre>"},{"location":"deployment/#2-secrets","title":"2. Secrets","text":"<pre><code># Create secrets from environment file\nkubectl create secret generic forge-secrets \\\n  --from-env-file=.env.prod \\\n  --namespace forge\n</code></pre>"},{"location":"deployment/#3-configmap","title":"3. ConfigMap","text":"<pre><code># k8s/configmap.yaml\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: forge-config\n  namespace: forge\ndata:\n  APP_ENV: \"production\"\n  LOG_LEVEL: \"INFO\"\n  ENABLE_TRACING: \"true\"\n</code></pre>"},{"location":"deployment/#4-deployment","title":"4. Deployment","text":"<pre><code># k8s/deployment.yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: forge-backend\n  namespace: forge\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: forge-backend\n  template:\n    metadata:\n      labels:\n        app: forge-backend\n    spec:\n      containers:\n      - name: forge-backend\n        image: forge-backend:latest\n        ports:\n        - containerPort: 8000\n        envFrom:\n        - configMapRef:\n            name: forge-config\n        - secretRef:\n            name: forge-secrets\n        livenessProbe:\n          httpGet:\n            path: /health\n            port: 8000\n          initialDelaySeconds: 30\n          periodSeconds: 10\n        readinessProbe:\n          httpGet:\n            path: /health\n            port: 8000\n          initialDelaySeconds: 5\n          periodSeconds: 5\n</code></pre>"},{"location":"deployment/#5-service","title":"5. Service","text":"<pre><code># k8s/service.yaml\napiVersion: v1\nkind: Service\nmetadata:\n  name: forge-backend\n  namespace: forge\nspec:\n  selector:\n    app: forge-backend\n  ports:\n  - port: 80\n    targetPort: 8000\n  type: ClusterIP\n</code></pre>"},{"location":"deployment/#6-ingress","title":"6. Ingress","text":"<pre><code># k8s/ingress.yaml\napiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: forge-backend\n  namespace: forge\n  annotations:\n    nginx.ingress.kubernetes.io/ssl-redirect: \"true\"\nspec:\n  tls:\n  - hosts:\n    - api.yourdomain.com\n    secretName: forge-tls\n  rules:\n  - host: api.yourdomain.com\n    http:\n      paths:\n      - path: /\n        pathType: Prefix\n        backend:\n          service:\n            name: forge-backend\n            port:\n              number: 80\n</code></pre>"},{"location":"deployment/#7-deploy-to-kubernetes","title":"7. Deploy to Kubernetes","text":"<pre><code># Apply configurations\nkubectl apply -f k8s/\n\n# Check deployment\nkubectl get pods -n forge\nkubectl get services -n forge\nkubectl get ingress -n forge\n</code></pre>"},{"location":"deployment/#ssltls-configuration","title":"SSL/TLS Configuration","text":""},{"location":"deployment/#lets-encrypt-with-cert-manager","title":"Let's Encrypt with cert-manager","text":"<pre><code># k8s/ingress.yaml (with cert-manager)\napiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: forge-backend\n  namespace: forge\n  annotations:\n    cert-manager.io/cluster-issuer: \"letsencrypt-prod\"\n    nginx.ingress.kubernetes.io/ssl-redirect: \"true\"\nspec:\n  tls:\n  - hosts:\n    - api.yourdomain.com\n    secretName: forge-tls\n  rules:\n  - host: api.yourdomain.com\n    http:\n      paths:\n      - path: /\n        pathType: Prefix\n        backend:\n          service:\n            name: forge-backend\n            port:\n              number: 80\n</code></pre>"},{"location":"deployment/#monitoring-setup","title":"Monitoring Setup","text":""},{"location":"deployment/#jaeger-tracing","title":"Jaeger Tracing","text":"<pre><code># docker-compose.prod.yml (add jaeger)\nservices:\n  jaeger:\n    image: jaegertracing/all-in-one:latest\n    ports:\n      - \"16686:16686\"\n    environment:\n      - COLLECTOR_OTLP_ENABLED=true\n    restart: unless-stopped\n</code></pre>"},{"location":"deployment/#prometheus-metrics","title":"Prometheus Metrics","text":"<p>Add Prometheus annotations to deployment:</p> <pre><code># k8s/deployment.yaml\nmetadata:\n  annotations:\n    prometheus.io/scrape: \"true\"\n    prometheus.io/port: \"8000\"\n    prometheus.io/path: \"/metrics\"\n</code></pre>"},{"location":"deployment/#background-tasks","title":"Background Tasks","text":""},{"location":"deployment/#celery-worker-deployment","title":"Celery Worker Deployment","text":"<pre><code># k8s/celery-worker.yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: forge-worker\n  namespace: forge\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: forge-worker\n  template:\n    metadata:\n      labels:\n        app: forge-worker\n    spec:\n      containers:\n      - name: celery-worker\n        image: forge-backend:latest\n        command: [\"celery\", \"worker\", \"-A\", \"forge.celery_app\", \"--loglevel=info\"]\n        envFrom:\n        - configMapRef:\n            name: forge-config\n        - secretRef:\n            name: forge-secrets\n</code></pre>"},{"location":"deployment/#scaling","title":"Scaling","text":""},{"location":"deployment/#horizontal-pod-autoscaling","title":"Horizontal Pod Autoscaling","text":"<pre><code># k8s/hpa.yaml\napiVersion: autoscaling/v2\nkind: HorizontalPodAutoscaler\nmetadata:\n  name: forge-backend-hpa\n  namespace: forge\nspec:\n  scaleTargetRef:\n    apiVersion: apps/v1\n    kind: Deployment\n    name: forge-backend\n  minReplicas: 2\n  maxReplicas: 10\n  metrics:\n  - type: Resource\n    resource:\n      name: cpu\n      target:\n        type: Utilization\n        averageUtilization: 70\n  - type: Resource\n    resource:\n      name: memory\n      target:\n        type: Utilization\n        averageUtilization: 80\n</code></pre>"},{"location":"deployment/#backup-and-recovery","title":"Backup and Recovery","text":""},{"location":"deployment/#redis-backup","title":"Redis Backup","text":"<pre><code># Backup Redis data\ndocker exec forge-redis redis-cli SAVE\n\n# Copy backup from container\ndocker cp forge-redis:/data/dump.rdb ./backup/redis-$(date +%Y%m%d).rdb\n</code></pre>"},{"location":"deployment/#database-backup-if-applicable","title":"Database Backup (if applicable)","text":"<pre><code># Add database backup cron job\nkubectl create job --from=cronjob/backup-job backup-$(date +%s)\n</code></pre>"},{"location":"deployment/#troubleshooting","title":"Troubleshooting","text":""},{"location":"deployment/#common-issues","title":"Common Issues","text":"<ol> <li>Pods not starting: Check logs with <code>kubectl logs -n forge deployment/forge-backend</code></li> <li>Health checks failing: Verify environment variables and service dependencies</li> <li>High memory usage: Adjust resource limits or investigate memory leaks</li> <li>Slow responses: Check Redis connectivity and background task queues</li> </ol>"},{"location":"deployment/#debug-commands","title":"Debug Commands","text":"<pre><code># Check pod status\nkubectl get pods -n forge\n\n# View logs\nkubectl logs -f -n forge deployment/forge-backend\n\n# Exec into pod\nkubectl exec -it -n forge deployment/forge-backend -- /bin/bash\n\n# Check service endpoints\nkubectl get endpoints -n forge\n</code></pre>"},{"location":"deployment/#performance-tuning","title":"Performance Tuning","text":""},{"location":"deployment/#resource-limits","title":"Resource Limits","text":"<pre><code># k8s/deployment.yaml\nresources:\n  requests:\n    memory: \"256Mi\"\n    cpu: \"100m\"\n  limits:\n    memory: \"512Mi\"\n    cpu: \"500m\"\n</code></pre>"},{"location":"deployment/#environment-variables","title":"Environment Variables","text":"<pre><code># Production optimizations\nWORKERS=4\nMAX_REQUESTS=1000\nMAX_REQUESTS_JITTER=50\n</code></pre>"},{"location":"deployment/#security-considerations","title":"Security Considerations","text":"<ul> <li>Run containers as non-root user</li> <li>Use read-only root filesystem where possible</li> <li>Implement network policies</li> <li>Regular security updates</li> <li>Secret rotation</li> <li>Audit logging</li> </ul>"},{"location":"development-setup/","title":"Development Setup","text":"<p>This guide covers setting up a development environment for ForgeTM Backend.</p>"},{"location":"development-setup/#prerequisites","title":"Prerequisites","text":""},{"location":"development-setup/#system-requirements","title":"System Requirements","text":"<ul> <li>Python 3.11+: The backend requires Python 3.11 or higher</li> <li>uv: Modern Python package manager (faster than pip)</li> <li>Git: Version control</li> <li>Docker &amp; Docker Compose: For containerized services</li> </ul>"},{"location":"development-setup/#optional-tools","title":"Optional Tools","text":"<ul> <li>Ollama: For local AI model testing</li> <li>Jaeger: For distributed tracing visualization</li> <li>VS Code: Recommended IDE with Python extensions</li> </ul>"},{"location":"development-setup/#installation","title":"Installation","text":""},{"location":"development-setup/#1-clone-the-repository","title":"1. Clone the Repository","text":"<pre><code>git clone &lt;repository-url&gt;\ncd ForgeMonorepo/ForgeTM/apps/backend\n</code></pre>"},{"location":"development-setup/#2-install-uv-if-not-already-installed","title":"2. Install uv (if not already installed)","text":"<pre><code># macOS\ncurl -LsSf https://astral.sh/uv/install.sh | sh\n\n# Linux\ncurl -LsSf https://astral.sh/uv/install.sh | sh\n\n# Windows (PowerShell)\npowershell -c \"irm https://astral.sh/uv/install.sh | iex\"\n</code></pre>"},{"location":"development-setup/#3-install-dependencies","title":"3. Install Dependencies","text":"<pre><code># Install all dependencies (including dev dependencies)\nuv sync\n\n# Verify installation\nuv run python -c \"import forge; print('Installation successful')\"\n</code></pre>"},{"location":"development-setup/#4-environment-configuration","title":"4. Environment Configuration","text":"<pre><code># Copy the example environment file\ncp .env.example .env\n\n# The default .env.example should work for basic development\n# Edit .env if you need to customize settings\n</code></pre>"},{"location":"development-setup/#running-the-application","title":"Running the Application","text":""},{"location":"development-setup/#development-server","title":"Development Server","text":"<pre><code># Start with auto-reload\nuv run uvicorn forge.main:app --reload --host 127.0.0.1 --port 8000\n\n# Or using Python directly\npython -m uvicorn forge.main:app --reload\n</code></pre>"},{"location":"development-setup/#with-docker-compose","title":"With Docker Compose","text":"<pre><code># Start all services (backend, redis, etc.)\ndocker-compose up -d\n\n# View logs\ndocker-compose logs -f backend\n\n# Stop services\ndocker-compose down\n</code></pre>"},{"location":"development-setup/#development-workflow","title":"Development Workflow","text":""},{"location":"development-setup/#code-changes","title":"Code Changes","text":"<ol> <li>Make changes to source code in <code>src/forge/</code></li> <li>Run tests to ensure changes work correctly</li> <li>Check linting and formatting</li> <li>Test manually using API endpoints</li> </ol>"},{"location":"development-setup/#testing","title":"Testing","text":"<pre><code># Run all tests\nuv run pytest\n\n# Run with coverage\nuv run pytest --cov=forge --cov-report=html\n\n# Run specific test file\nuv run pytest tests/test_tasks.py\n\n# Run tests in watch mode (if pytest-watch installed)\nuv run ptw\n</code></pre>"},{"location":"development-setup/#code-quality","title":"Code Quality","text":"<pre><code># Linting\nuv run ruff check .\n\n# Auto-fix linting issues\nuv run ruff check --fix .\n\n# Formatting\nuv run ruff format .\n\n# Type checking\nuv run mypy src/\n</code></pre>"},{"location":"development-setup/#documentation","title":"Documentation","text":"<pre><code># Serve documentation locally\nuv run mkdocs serve\n\n# Build documentation\nuv run mkdocs build\n</code></pre>"},{"location":"development-setup/#ide-setup","title":"IDE Setup","text":""},{"location":"development-setup/#vs-code","title":"VS Code","text":"<p>Install recommended extensions:</p> <ul> <li>Python (Microsoft)</li> <li>Pylance (Microsoft)</li> <li>Ruff (charliermarsh)</li> <li>Python Debugger (Microsoft)</li> </ul> <p>Create <code>.vscode/settings.json</code>:</p> <pre><code>{\n  \"python.defaultInterpreterPath\": \"./.venv/bin/python\",\n  \"python.linting.enabled\": true,\n  \"python.linting.ruffEnabled\": true,\n  \"python.formatting.provider\": \"ruff\",\n  \"python.analysis.typeCheckingMode\": \"standard\",\n  \"editor.formatOnSave\": true,\n  \"editor.codeActionsOnSave\": {\n    \"source.fixAll.ruff\": \"explicit\",\n    \"source.organizeImports.ruff\": \"explicit\"\n  }\n}\n</code></pre>"},{"location":"development-setup/#pycharmintellij","title":"PyCharm/IntelliJ","text":"<ol> <li>Open project in IDE</li> <li>Configure Python interpreter: <code>File \u2192 Settings \u2192 Project \u2192 Python Interpreter \u2192 Add \u2192 Virtualenv Environment \u2192 Select .venv/bin/python</code></li> <li>Enable Ruff integration in plugins</li> <li>Configure run/debug configurations for FastAPI</li> </ol>"},{"location":"development-setup/#debugging","title":"Debugging","text":""},{"location":"development-setup/#local-debugging","title":"Local Debugging","text":"<pre><code># Run with debug logging\nLOG_LEVEL=DEBUG uv run uvicorn forge.main:app --reload\n\n# Or set in .env\n# LOG_LEVEL=DEBUG\n</code></pre>"},{"location":"development-setup/#vs-code-debugging","title":"VS Code Debugging","text":"<p>Create <code>.vscode/launch.json</code>:</p> <pre><code>{\n  \"version\": \"0.2.0\",\n  \"configurations\": [\n    {\n      \"name\": \"FastAPI\",\n      \"type\": \"python\",\n      \"request\": \"launch\",\n      \"module\": \"uvicorn\",\n      \"args\": [\"forge.main:app\", \"--reload\", \"--host\", \"127.0.0.1\", \"--port\", \"8000\"],\n      \"cwd\": \"${workspaceFolder}/ForgeTM/apps/backend\",\n      \"python\": \"./.venv/bin/python\",\n      \"console\": \"integratedTerminal\"\n    },\n    {\n      \"name\": \"Tests\",\n      \"type\": \"python\",\n      \"request\": \"launch\",\n      \"module\": \"pytest\",\n      \"args\": [\"tests/\"],\n      \"cwd\": \"${workspaceFolder}/ForgeTM/apps/backend\",\n      \"python\": \"./.venv/bin/python\"\n    }\n  ]\n}\n</code></pre>"},{"location":"development-setup/#remote-debugging","title":"Remote Debugging","text":"<p>For debugging in Docker containers:</p> <pre><code># Run with debugpy\nuv run python -m debugpy --listen 0.0.0.0:5678 -m uvicorn forge.main:app --host 0.0.0.0 --port 8000\n</code></pre>"},{"location":"development-setup/#testing-external-services","title":"Testing External Services","text":""},{"location":"development-setup/#ollama-setup","title":"Ollama Setup","text":"<pre><code># Install Ollama (macOS)\nbrew install ollama\n\n# Start Ollama service\nollama serve\n\n# Pull a test model\nollama pull llama2:7b\n\n# Verify\ncurl http://localhost:11434/api/tags\n</code></pre>"},{"location":"development-setup/#litellm-setup","title":"LiteLLM Setup","text":"<pre><code># Install LiteLLM\npip install litellm\n\n# Start proxy (in another terminal)\nlitellm --model gpt-3.5-turbo --api_key your-openai-key\n\n# Or use Docker\ndocker run -p 4000:4000 ghcr.io/berriai/litellm:main --model gpt-3.5-turbo --api_key your-openai-key\n</code></pre>"},{"location":"development-setup/#jaeger-setup","title":"Jaeger Setup","text":"<pre><code># Start Jaeger for tracing\ndocker run -d --name jaeger \\\n  -p 16686:16686 \\\n  -p 4318:4318 \\\n  jaegertracing/all-in-one:latest\n\n# View traces at http://localhost:16686\n</code></pre>"},{"location":"development-setup/#background-tasks","title":"Background Tasks","text":""},{"location":"development-setup/#running-celery-worker","title":"Running Celery Worker","text":"<pre><code># Start worker for background tasks\nuv run celery worker -A forge.celery_app --loglevel=info\n\n# Or with beat scheduler\nuv run celery worker -A forge.celery_app --loglevel=info --beat\n</code></pre>"},{"location":"development-setup/#testing-background-tasks","title":"Testing Background Tasks","text":"<pre><code># In Python REPL\nfrom forge.tasks import health_check_task\nresult = health_check_task.delay()\nprint(result.get())\n</code></pre>"},{"location":"development-setup/#database-setup-if-applicable","title":"Database Setup (if applicable)","text":"<p>If your application uses a database:</p> <pre><code># Start PostgreSQL\ndocker run -d --name postgres \\\n  -e POSTGRES_PASSWORD=password \\\n  -e POSTGRES_DB=forge \\\n  -p 5432:5432 \\\n  postgres:15\n\n# Run migrations (if using Alembic)\nuv run alembic upgrade head\n</code></pre>"},{"location":"development-setup/#performance-profiling","title":"Performance Profiling","text":""},{"location":"development-setup/#memory-profiling","title":"Memory Profiling","text":"<pre><code># Install memory profiler\nuv add memory-profiler --dev\n\n# Profile a function\nuv run python -m memory_profiler forge/tasks.py\n</code></pre>"},{"location":"development-setup/#cpu-profiling","title":"CPU Profiling","text":"<pre><code># Install py-spy\npip install py-spy\n\n# Profile running application\npy-spy top --pid $(pgrep -f uvicorn)\n</code></pre>"},{"location":"development-setup/#contributing","title":"Contributing","text":""},{"location":"development-setup/#pre-commit-hooks","title":"Pre-commit Hooks","text":"<pre><code># Install pre-commit\nuv run pre-commit install\n\n# Run on all files\nuv run pre-commit run --all-files\n</code></pre>"},{"location":"development-setup/#git-workflow","title":"Git Workflow","text":"<ol> <li>Create feature branch: <code>git checkout -b feature/my-feature</code></li> <li>Make changes and commit: <code>git commit -m \"feat: add my feature\"</code></li> <li>Push and create PR: <code>git push origin feature/my-feature</code></li> </ol>"},{"location":"development-setup/#commit-conventions","title":"Commit Conventions","text":"<ul> <li><code>feat:</code> - New features</li> <li><code>fix:</code> - Bug fixes</li> <li><code>docs:</code> - Documentation</li> <li><code>refactor:</code> - Code restructuring</li> <li><code>test:</code> - Testing</li> <li><code>chore:</code> - Maintenance</li> </ul>"},{"location":"development-setup/#troubleshooting","title":"Troubleshooting","text":""},{"location":"development-setup/#common-issues","title":"Common Issues","text":"<ol> <li>Import errors: Ensure virtual environment is activated</li> <li>Port already in use: Change port in <code>.env</code> or kill process</li> <li>Redis connection failed: Start Redis with <code>docker-compose up redis</code></li> <li>Ollama not responding: Check if Ollama service is running</li> </ol>"},{"location":"development-setup/#getting-help","title":"Getting Help","text":"<ul> <li>Check application logs: <code>docker-compose logs backend</code></li> <li>Enable debug logging: <code>LOG_LEVEL=DEBUG</code></li> <li>Check health endpoints: <code>curl http://localhost:8000/health</code></li> <li>Review documentation: <code>mkdocs serve</code></li> </ul>"},{"location":"getting-started/","title":"Getting Started","text":"<p>This guide will help you get ForgeTM Backend up and running quickly.</p>"},{"location":"getting-started/#prerequisites","title":"Prerequisites","text":"<p>Before you begin, ensure you have the following installed:</p> <ul> <li>Python 3.11+: The backend requires Python 3.11 or higher</li> <li>uv: Modern Python package manager for fast dependency management</li> <li>Docker &amp; Docker Compose: For containerized development and deployment</li> <li>Git: For version control</li> </ul>"},{"location":"getting-started/#optional-dependencies","title":"Optional Dependencies","text":"<ul> <li>Ollama: For local AI model hosting</li> <li>Redis: For background task queuing (automatically provided via Docker)</li> </ul>"},{"location":"getting-started/#installation","title":"Installation","text":""},{"location":"getting-started/#1-clone-the-repository","title":"1. Clone the Repository","text":"<pre><code>git clone &lt;repository-url&gt;\ncd ForgeMonorepo/ForgeTM/apps/backend\n</code></pre>"},{"location":"getting-started/#2-install-dependencies","title":"2. Install Dependencies","text":"<pre><code># Install Python dependencies\nuv sync\n\n# Verify installation\nuv run python -c \"import forge; print('Installation successful')\"\n</code></pre>"},{"location":"getting-started/#3-environment-configuration","title":"3. Environment Configuration","text":"<pre><code># Copy the example environment file\ncp .env.example .env\n\n# Edit the environment file with your settings\n# At minimum, you'll need to configure:\n# - OLLAMA_BASE_URL (if using Ollama)\n# - LITELLM_PROXY_URL (if using LiteLLM)\n# - REDIS_URL (for background tasks)\n</code></pre>"},{"location":"getting-started/#4-start-development-services","title":"4. Start Development Services","text":"<pre><code># Start Redis and other services\ndocker-compose up -d redis\n\n# Or start all services\ndocker-compose up -d\n</code></pre>"},{"location":"getting-started/#5-run-the-application","title":"5. Run the Application","text":"<pre><code># Development mode with auto-reload\nuvicorn forge.main:app --reload --host 127.0.0.1 --port 8000\n\n# Or using uv\nuv run uvicorn forge.main:app --reload\n</code></pre>"},{"location":"getting-started/#verification","title":"Verification","text":""},{"location":"getting-started/#health-check","title":"Health Check","text":"<p>Once the application is running, verify it's working:</p> <pre><code>curl http://localhost:8000/health\n</code></pre> <p>Expected response:</p> <pre><code>{\n  \"status\": \"ok\",\n  \"version\": \"0.1.0\",\n  \"uptime_sec\": 123.456\n}\n</code></pre>"},{"location":"getting-started/#api-documentation","title":"API Documentation","text":"<p>Access the interactive API documentation:</p> <ul> <li>Swagger UI: http://localhost:8000/docs</li> <li>ReDoc: http://localhost:8000/redoc</li> <li>OpenAPI Schema: http://localhost:8000/openapi.json</li> </ul>"},{"location":"getting-started/#next-steps","title":"Next Steps","text":"<ul> <li>Configure your AI providers</li> <li>Learn about the API</li> <li>Set up development environment</li> <li>Deploy to production</li> </ul>"},{"location":"testing/","title":"Testing","text":"<p>This guide covers the testing strategy and practices for ForgeTM Backend.</p>"},{"location":"testing/#testing-philosophy","title":"Testing Philosophy","text":"<p>ForgeTM Backend follows a comprehensive testing approach:</p> <ul> <li>Unit Tests: Test individual functions and classes in isolation</li> <li>Integration Tests: Test component interactions and external service calls</li> <li>End-to-End Tests: Test complete user workflows (future)</li> <li>Property-Based Tests: Test with generated input data using Hypothesis</li> </ul>"},{"location":"testing/#test-structure","title":"Test Structure","text":"<pre><code>tests/\n\u251c\u2500\u2500 __init__.py\n\u251c\u2500\u2500 conftest.py              # Pytest configuration and fixtures\n\u251c\u2500\u2500 test_health.py           # Health endpoint tests\n\u251c\u2500\u2500 test_tasks.py            # Background task tests\n\u251c\u2500\u2500 test_providers.py        # Provider API tests\n\u251c\u2500\u2500 test_ollama.py           # Ollama integration tests\n\u2514\u2500\u2500 integration/             # Integration tests\n    \u251c\u2500\u2500 test_api_integration.py\n    \u2514\u2500\u2500 test_background_tasks_integration.py\n</code></pre>"},{"location":"testing/#running-tests","title":"Running Tests","text":""},{"location":"testing/#basic-test-execution","title":"Basic Test Execution","text":"<pre><code># Run all tests\nuv run pytest\n\n# Run with verbose output\nuv run pytest -v\n\n# Run specific test file\nuv run pytest tests/test_tasks.py\n\n# Run specific test function\nuv run pytest tests/test_tasks.py::test_health_check_task\n\n# Run tests matching pattern\nuv run pytest -k \"health\"\n</code></pre>"},{"location":"testing/#test-coverage","title":"Test Coverage","text":"<pre><code># Generate coverage report\nuv run pytest --cov=forge --cov-report=html\n\n# View HTML report\nopen htmlcov/index.html\n\n# Coverage with minimum threshold\nuv run pytest --cov=forge --cov-fail-under=90\n</code></pre>"},{"location":"testing/#test-categories","title":"Test Categories","text":"<pre><code># Run only unit tests\nuv run pytest -m \"not integration\"\n\n# Run only integration tests\nuv run pytest -m integration\n\n# Run only performance tests\nuv run pytest -m performance\n</code></pre>"},{"location":"testing/#writing-tests","title":"Writing Tests","text":""},{"location":"testing/#unit-test-example","title":"Unit Test Example","text":"<pre><code>import pytest\nfrom forge.tasks import health_check_task\n\n\nclass TestHealthCheckTask:\n    \"\"\"Test cases for health check background task.\"\"\"\n\n    @pytest.mark.asyncio\n    async def test_health_check_success(self):\n        \"\"\"Test successful health check.\"\"\"\n        result = await health_check_task()\n        assert result[\"status\"] == \"ok\"\n        assert \"timestamp\" in result\n\n    @pytest.mark.asyncio\n    async def test_health_check_with_error(self):\n        \"\"\"Test health check with simulated error.\"\"\"\n        # Mock external dependency failure\n        with patch(\"httpx.AsyncClient.get\", side_effect=Exception(\"Connection failed\")):\n            result = await health_check_task()\n            assert result[\"status\"] == \"error\"\n            assert \"error\" in result\n</code></pre>"},{"location":"testing/#integration-test-example","title":"Integration Test Example","text":"<pre><code>import pytest\nfrom httpx import AsyncClient\nfrom forge.main import app\n\n\n@pytest.mark.integration\nclass TestAPIIntegration:\n    \"\"\"Integration tests for API endpoints.\"\"\"\n\n    @pytest.fixture\n    async def client(self):\n        \"\"\"Create test client.\"\"\"\n        async with AsyncClient(app=app, base_url=\"http://testserver\") as client:\n            yield client\n\n    async def test_health_endpoint(self, client):\n        \"\"\"Test health endpoint returns correct response.\"\"\"\n        response = await client.get(\"/health\")\n        assert response.status_code == 200\n        data = response.json()\n        assert data[\"status\"] == \"ok\"\n        assert \"version\" in data\n\n    async def test_providers_health_endpoint(self, client):\n        \"\"\"Test providers health endpoint.\"\"\"\n        response = await client.get(\"/providers/health\")\n        assert response.status_code == 200\n        data = response.json()\n        assert \"providers\" in data\n        assert \"ollama\" in data[\"providers\"]\n</code></pre>"},{"location":"testing/#property-based-testing","title":"Property-Based Testing","text":"<pre><code>import pytest\nfrom hypothesis import given, strategies as st\nfrom forge.api.ollama import OllamaModel\n\n\nclass TestOllamaModel:\n    \"\"\"Property-based tests for Ollama model structures.\"\"\"\n\n    @given(\n        name=st.text(min_size=1, max_size=100),\n        size=st.integers(min_value=0, max_value=10**12),\n        digest=st.one_of(st.none(), st.text(min_size=1, max_size=100))\n    )\n    def test_ollama_model_creation(self, name, size, digest):\n        \"\"\"Test OllamaModel can be created with various inputs.\"\"\"\n        model = OllamaModel(name=name, size=size, digest=digest)\n        assert model.name == name\n        assert model.size == size\n        assert model.digest == digest\n</code></pre>"},{"location":"testing/#test-fixtures","title":"Test Fixtures","text":""},{"location":"testing/#conftestpy","title":"conftest.py","text":"<pre><code>import pytest\nimport redis\nfrom unittest.mock import AsyncMock\nfrom forge.config import Settings\n\n\n@pytest.fixture\ndef settings():\n    \"\"\"Create test settings.\"\"\"\n    return Settings(\n        app_env=\"testing\",\n        redis_url=\"redis://localhost:6379/1\",  # Separate test database\n        enable_tracing=False\n    )\n\n\n@pytest.fixture\nasync def redis_client(settings):\n    \"\"\"Create Redis client for testing.\"\"\"\n    client = redis.from_url(settings.redis_url)\n    yield client\n    # Clean up after test\n    client.flushdb()\n\n\n@pytest.fixture\ndef mock_httpx_client():\n    \"\"\"Mock httpx client for external API calls.\"\"\"\n    with patch(\"httpx.AsyncClient\") as mock_client:\n        mock_instance = AsyncMock()\n        mock_client.return_value.__aenter__.return_value = mock_instance\n        yield mock_instance\n</code></pre>"},{"location":"testing/#mocking-external-services","title":"Mocking External Services","text":""},{"location":"testing/#http-client-mocking","title":"HTTP Client Mocking","text":"<pre><code>from unittest.mock import patch, AsyncMock\nimport pytest\n\n\n@pytest.mark.asyncio\nasync def test_ollama_list_models_success():\n    \"\"\"Test successful Ollama model listing.\"\"\"\n    mock_response = AsyncMock()\n    mock_response.status_code = 200\n    mock_response.json.return_value = {\n        \"models\": [\n            {\"name\": \"llama2:7b\", \"size\": 3791737152, \"digest\": \"sha256:123\"}\n        ]\n    }\n\n    with patch(\"httpx.AsyncClient.get\", return_value=mock_response) as mock_get:\n        from forge.api.ollama import list_models\n        models = await list_models()\n\n        assert len(models) == 1\n        assert models[0].name == \"llama2:7b\"\n        mock_get.assert_called_once()\n</code></pre>"},{"location":"testing/#redis-mocking","title":"Redis Mocking","text":"<pre><code>from unittest.mock import patch\nimport pytest\n\n\n@pytest.mark.asyncio\nasync def test_background_task_with_redis():\n    \"\"\"Test background task that uses Redis.\"\"\"\n    with patch(\"redis.Redis\") as mock_redis:\n        mock_client = AsyncMock()\n        mock_redis.from_url.return_value = mock_client\n\n        from forge.tasks import some_redis_task\n        result = await some_redis_task()\n\n        assert result[\"status\"] == \"success\"\n        mock_client.set.assert_called_with(\"some_key\", \"some_value\")\n</code></pre>"},{"location":"testing/#test-configuration","title":"Test Configuration","text":""},{"location":"testing/#pytestini","title":"pytest.ini","text":"<pre><code>[tool:pytest]\ntestpaths = tests\npython_files = test_*.py\npython_classes = Test*\npython_functions = test_*\naddopts =\n    --strict-markers\n    --strict-config\n    --cov=forge\n    --cov-report=term-missing\n    --cov-fail-under=90\nmarkers =\n    integration: marks tests as integration tests (deselect with '-m \"not integration\"')\n    performance: marks tests as performance tests\n    slow: marks tests as slow (deselect with '-m \"not slow\"')\nasyncio_mode = auto\n</code></pre>"},{"location":"testing/#coverage-configuration","title":"Coverage Configuration","text":"<pre><code>[coverage:run]\nsource = forge\nomit =\n    */tests/*\n    */venv/*\n    */.venv/*\n\n[coverage:report]\nexclude_lines =\n    pragma: no cover\n    def __repr__\n    raise AssertionError\n    raise NotImplementedError\n</code></pre>"},{"location":"testing/#continuous-integration","title":"Continuous Integration","text":""},{"location":"testing/#github-actions-example","title":"GitHub Actions Example","text":"<pre><code>name: Tests\non: [push, pull_request]\n\njobs:\n  test:\n    runs-on: ubuntu-latest\n    services:\n      redis:\n        image: redis:7\n        ports:\n          - 6379:6379\n      ollama:\n        image: ollama/ollama:latest\n        ports:\n          - 11434:11434\n\n    steps:\n    - uses: actions/checkout@v4\n    - uses: astral-sh/setup-uv@v1\n    - run: uv sync\n    - run: uv run pytest --cov=forge --cov-report=xml\n    - uses: codecov/codecov-action@v3\n</code></pre>"},{"location":"testing/#performance-testing","title":"Performance Testing","text":""},{"location":"testing/#load-testing-with-pytest-benchmark","title":"Load Testing with pytest-benchmark","text":"<pre><code>import pytest\nfrom forge.tasks import health_check_task\n\n\n@pytest.mark.performance\nclass TestPerformance:\n    \"\"\"Performance tests for critical functions.\"\"\"\n\n    def test_health_check_performance(self, benchmark):\n        \"\"\"Benchmark health check task performance.\"\"\"\n        result = benchmark(health_check_task)\n        assert result[\"status\"] == \"ok\"\n        assert benchmark.stats[\"mean\"] &lt; 1.0  # Should complete in &lt; 1 second\n</code></pre>"},{"location":"testing/#memory-usage-testing","title":"Memory Usage Testing","text":"<pre><code>import pytest\nimport tracemalloc\nfrom forge.tasks import analytics_aggregation_task\n\n\n@pytest.mark.performance\nclass TestMemoryUsage:\n    \"\"\"Memory usage tests.\"\"\"\n\n    def test_memory_usage_under_limit(self):\n        \"\"\"Ensure task doesn't use excessive memory.\"\"\"\n        tracemalloc.start()\n        result = analytics_aggregation_task()\n        current, peak = tracemalloc.get_traced_memory()\n        tracemalloc.stop()\n\n        # Assert memory usage is reasonable\n        assert peak &lt; 50 * 1024 * 1024  # Less than 50MB\n        assert result[\"status\"] == \"success\"\n</code></pre>"},{"location":"testing/#test-data-management","title":"Test Data Management","text":""},{"location":"testing/#test-database-isolation","title":"Test Database Isolation","text":"<pre><code>@pytest.fixture(autouse=True)\ndef isolate_redis_database(settings):\n    \"\"\"Ensure each test uses a separate Redis database.\"\"\"\n    # Use database 1 for tests (configured in settings fixture)\n    yield\n    # Clean up after each test\n    client = redis.from_url(settings.redis_url)\n    client.flushdb()\n</code></pre>"},{"location":"testing/#mock-data-factories","title":"Mock Data Factories","text":"<pre><code>from pydantic import BaseModel\n\n\nclass OllamaModelFactory:\n    \"\"\"Factory for creating test Ollama model data.\"\"\"\n\n    @staticmethod\n    def create_model(name=\"test-model\", size=1000000, digest=\"sha256:test\"):\n        \"\"\"Create a test Ollama model.\"\"\"\n        return {\n            \"name\": name,\n            \"size\": size,\n            \"digest\": digest\n        }\n\n    @staticmethod\n    def create_models(count=3):\n        \"\"\"Create multiple test models.\"\"\"\n        return [OllamaModelFactory.create_model(f\"model-{i}\") for i in range(count)]\n</code></pre>"},{"location":"testing/#debugging-tests","title":"Debugging Tests","text":""},{"location":"testing/#verbose-test-output","title":"Verbose Test Output","text":"<pre><code># Show all output\nuv run pytest -v -s\n\n# Show captured output on failure\nuv run pytest --tb=short\n\n# Debug specific test\nuv run pytest tests/test_tasks.py::TestHealthCheckTask::test_health_check_success -v -s\n</code></pre>"},{"location":"testing/#pdb-debugging","title":"PDB Debugging","text":"<pre><code>import pdb; pdb.set_trace()\n# Or add to pytest\nuv run pytest --pdb\n</code></pre>"},{"location":"testing/#best-practices","title":"Best Practices","text":"<ol> <li>Test Isolation: Each test should be independent</li> <li>Descriptive Names: Test names should describe what they test</li> <li>Arrange-Act-Assert: Structure tests clearly</li> <li>Mock External Dependencies: Don't rely on external services</li> <li>Test Edge Cases: Include boundary conditions and error cases</li> <li>Maintain Test Coverage: Keep coverage above 90%</li> <li>Fast Tests: Keep unit tests under 100ms each</li> <li>Documentation: Document complex test scenarios</li> </ol>"}]}